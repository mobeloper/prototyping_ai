{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mgfrantz/CTME-llm-lecture-resources/blob/main/prototyping_ai/02_rag_and_agents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eTnsbyXHSknb"
   },
   "source": [
    "# Retrieval Augmented Generation\n",
    "\n",
    "![](https://www.dailydoseofds.com/content/images/2024/10/rag.gif)\n",
    "Source: [Daily Dose of DS](https://www.dailydoseofds.com/a-crash-course-on-building-rag-systems-part-1-with-implementations/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "8LukVZNkSknb"
   },
   "outputs": [],
   "source": [
    "%load_ext rich\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UZ_s5wYLSknc"
   },
   "source": [
    "# Introduction to RAG with LlamaIndex\n",
    "\n",
    "LlamaIndex is a library for working with large language models.\n",
    "One of its main strengths is its ability to ingest documents into a vector index and use them to answer questions.\n",
    "This is known as Retrieval Augmented Generation (RAG).\n",
    "\n",
    "To start, we will use a low-code, high-level abstraction to build a basic PDF question-answering system.\n",
    "We will read in PDFs, split them into chunks, embed them, and store them in a vector database.\n",
    "Then, we will use an abstraction known as a `QueryEngine` that implements RAG to answer questions about the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 6789,
     "status": "ok",
     "timestamp": 1733615612825,
     "user": {
      "displayName": "Eric Michel",
      "userId": "07676971985746424800"
     },
     "user_tz": 480
    },
    "id": "61Q9189dSknc",
    "outputId": "34c8bbb7-8a90-4580-baa1-6a160760deb2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Colab detected - setting up environment\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Colab detected - setting up environment\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index in /usr/local/lib/python3.10/dist-packages (0.12.3)\n",
      "Requirement already satisfied: openai==1.55.3 in /usr/local/lib/python3.10/dist-packages (1.55.3)\n",
      "Requirement already satisfied: httpx==0.27.2 in /usr/local/lib/python3.10/dist-packages (0.27.2)\n",
      "Requirement already satisfied: llama-index-readers-web in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
      "Requirement already satisfied: thefuzz in /usr/local/lib/python3.10/dist-packages (0.22.1)\n",
      "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (5.8.0)\n",
      "Requirement already satisfied: chromadb in /usr/local/lib/python3.10/dist-packages (0.5.23)\n",
      "Requirement already satisfied: llama-index-embeddings-huggingface in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
      "Requirement already satisfied: llama-index-vector-stores-chroma in /usr/local/lib/python3.10/dist-packages (0.4.1)\n",
      "Requirement already satisfied: llama-index-retrievers-bm25 in /usr/local/lib/python3.10/dist-packages (0.5.0)\n",
      "Requirement already satisfied: llama-index-llms-gemini in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
      "Requirement already satisfied: docling in /usr/local/lib/python3.10/dist-packages (2.8.3)\n",
      "Requirement already satisfied: llama-index-readers-docling in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
      "Requirement already satisfied: llama-index-node-parser-docling in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
      "Requirement already satisfied: llama-index-utils-workflow in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
      "Requirement already satisfied: llama-index-tools-yahoo-finance in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
      "Requirement already satisfied: llama-index-tools-code-interpreter in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.55.3) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.55.3) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.55.3) (0.8.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.55.3) (2.9.2)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai==1.55.3) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.55.3) (4.66.6)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai==1.55.3) (4.12.2)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.27.2) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.27.2) (1.0.7)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx==0.27.2) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx==0.27.2) (0.14.0)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.4.0)\n",
      "Requirement already satisfied: llama-index-cli<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.4.0)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.12.3)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.3.1)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.6.3)\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.9.48.post4)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.3.2)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.3.0)\n",
      "Requirement already satisfied: llama-index-program-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.3.1)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.3.0)\n",
      "Requirement already satisfied: llama-index-readers-file<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.4.1)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.4.0)\n",
      "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index) (3.9.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-web) (3.11.9)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-web) (4.12.3)\n",
      "Requirement already satisfied: chromedriver-autoinstaller<0.7.0,>=0.6.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-web) (0.6.4)\n",
      "Requirement already satisfied: html2text<2025.0.0,>=2024.2.26 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-web) (2024.2.26)\n",
      "Requirement already satisfied: newspaper3k<0.3.0,>=0.2.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-web) (0.2.8)\n",
      "Requirement already satisfied: playwright<2.0,>=1.30 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-web) (1.49.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-web) (2.32.3)\n",
      "Requirement already satisfied: selenium<5.0.0,>=4.17.2 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-web) (4.27.1)\n",
      "Requirement already satisfied: spider-client<0.0.28,>=0.0.27 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-web) (0.0.27)\n",
      "Requirement already satisfied: urllib3>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-web) (2.2.3)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from thefuzz) (3.10.1)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.115.6)\n",
      "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.4.0)\n",
      "Requirement already satisfied: gradio-client==1.5.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.26.3)\n",
      "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
      "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.12)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (10.4.0)\n",
      "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.19)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
      "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.8.2)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.41.3)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.13.2)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.5)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.32.1)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.1->gradio) (2024.10.0)\n",
      "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.1->gradio) (14.1)\n",
      "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.2.2.post1)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.7.6)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.7.4)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.20.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.48b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.27.0)\n",
      "Requirement already satisfied: tokenizers<=0.20.3,>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.20.3)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.4.5)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.68.1)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.2.1)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (31.0.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (8.5.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (5.0.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (13.9.4)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-embeddings-huggingface) (3.2.1)\n",
      "Requirement already satisfied: bm25s<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-retrievers-bm25) (0.2.5)\n",
      "Requirement already satisfied: pystemmer<3.0.0.0,>=2.2.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-retrievers-bm25) (2.2.0.3)\n",
      "Requirement already satisfied: google-generativeai<0.6.0,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-gemini) (0.5.4)\n",
      "Requirement already satisfied: deepsearch-glm<0.27.0,>=0.26.1 in /usr/local/lib/python3.10/dist-packages (from docling) (0.26.2)\n",
      "Requirement already satisfied: docling-core<3.0.0,>=2.6.1 in /usr/local/lib/python3.10/dist-packages (from docling) (2.8.0)\n",
      "Requirement already satisfied: docling-ibm-models<3.0.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from docling) (2.0.7)\n",
      "Requirement already satisfied: docling-parse<3.0.0,>=2.0.5 in /usr/local/lib/python3.10/dist-packages (from docling) (2.1.2)\n",
      "Requirement already satisfied: easyocr<2.0,>=1.7 in /usr/local/lib/python3.10/dist-packages (from docling) (1.7.2)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from docling) (1.2.0)\n",
      "Requirement already satisfied: lxml<6.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from docling) (5.3.0)\n",
      "Requirement already satisfied: marko<3.0.0,>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from docling) (2.1.2)\n",
      "Requirement already satisfied: openpyxl<4.0.0,>=3.1.5 in /usr/local/lib/python3.10/dist-packages (from docling) (3.1.5)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from docling) (2.6.1)\n",
      "Requirement already satisfied: pypdfium2<5.0.0,>=4.30.0 in /usr/local/lib/python3.10/dist-packages (from docling) (4.30.0)\n",
      "Requirement already satisfied: python-docx<2.0.0,>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from docling) (1.1.2)\n",
      "Requirement already satisfied: python-pptx<2.0.0,>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from docling) (1.0.2)\n",
      "Requirement already satisfied: rtree<2.0.0,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from docling) (1.3.0)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from docling) (1.13.1)\n",
      "Requirement already satisfied: pyvis<0.4.0,>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from llama-index-utils-workflow) (0.3.2)\n",
      "Requirement already satisfied: yfinance<0.3.0,>=0.2.36 in /usr/local/lib/python3.10/dist-packages (from llama-index-tools-yahoo-finance) (0.2.50)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->llama-index-readers-web) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->llama-index-readers-web) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->llama-index-readers-web) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->llama-index-readers-web) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->llama-index-readers-web) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->llama-index-readers-web) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->llama-index-readers-web) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->llama-index-readers-web) (1.18.3)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.55.3) (1.2.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-web) (2.6)\n",
      "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.2.1)\n",
      "Requirement already satisfied: docutils!=0.21 in /usr/local/lib/python3.10/dist-packages (from deepsearch-glm<0.27.0,>=0.26.1->docling) (0.21.2)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from deepsearch-glm<0.27.0,>=0.26.1->docling) (1.0.1)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from deepsearch-glm<0.27.0,>=0.26.1->docling) (0.9.0)\n",
      "Requirement already satisfied: jsonref<2.0.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from docling-core<3.0.0,>=2.6.1->docling) (1.1.0)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.16.0 in /usr/local/lib/python3.10/dist-packages (from docling-core<3.0.0,>=2.6.1->docling) (4.23.0)\n",
      "Requirement already satisfied: jsonlines<4.0.0,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from docling-ibm-models<3.0.0,>=2.0.6->docling) (3.1.0)\n",
      "Requirement already satisfied: opencv-python-headless<5.0.0.0,>=4.6.0.66 in /usr/local/lib/python3.10/dist-packages (from docling-ibm-models<3.0.0,>=2.0.6->docling) (4.10.0.84)\n",
      "Requirement already satisfied: torch<3.0.0,>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from docling-ibm-models<3.0.0,>=2.0.6->docling) (2.5.1+cu121)\n",
      "Requirement already satisfied: torchvision<1,>=0 in /usr/local/lib/python3.10/dist-packages (from docling-ibm-models<3.0.0,>=2.0.6->docling) (0.20.1+cu121)\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from easyocr<2.0,>=1.7->docling) (0.24.0)\n",
      "Requirement already satisfied: python-bidi in /usr/local/lib/python3.10/dist-packages (from easyocr<2.0,>=1.7->docling) (0.6.3)\n",
      "Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from easyocr<2.0,>=1.7->docling) (2.0.6)\n",
      "Requirement already satisfied: pyclipper in /usr/local/lib/python3.10/dist-packages (from easyocr<2.0,>=1.7->docling) (1.3.0.post6)\n",
      "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from easyocr<2.0,>=1.7->docling) (1.11.1.2)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.4 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (0.6.4)\n",
      "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (2.19.2)\n",
      "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (2.151.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (2.27.0)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (4.25.5)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.4->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (1.25.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.3->llama-index) (2.0.36)\n",
      "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.3->llama-index) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.3->llama-index) (1.2.15)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.3->llama-index) (1.0.8)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.3->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.3->llama-index) (3.4.2)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.3->llama-index) (0.8.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.3->llama-index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.3->llama-index) (1.17.0)\n",
      "Requirement already satisfied: llama-cloud>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.6)\n",
      "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (5.1.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (0.0.26)\n",
      "Requirement already satisfied: llama-parse>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.5.17)\n",
      "Requirement already satisfied: cssselect>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web) (1.2.0)\n",
      "Requirement already satisfied: feedparser>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web) (6.0.11)\n",
      "Requirement already satisfied: tldextract>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web) (5.1.3)\n",
      "Requirement already satisfied: feedfinder2>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web) (0.0.4)\n",
      "Requirement already satisfied: jieba3k>=0.35.1 in /usr/local/lib/python3.10/dist-packages (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web) (0.35.1)\n",
      "Requirement already satisfied: tinysegmenter==0.3 in /usr/local/lib/python3.10/dist-packages (from newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web) (0.3)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index) (2024.9.11)\n",
      "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
      "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl<4.0.0,>=3.1.5->docling) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata<=8.4.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.4.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.66.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.27.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.27.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.48b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.48b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.48b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.48b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.48b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.48b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.48b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.48b0)\n",
      "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (75.1.0)\n",
      "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-asgi==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
      "Requirement already satisfied: greenlet==3.1.1 in /usr/local/lib/python3.10/dist-packages (from playwright<2.0,>=1.30->llama-index-readers-web) (3.1.1)\n",
      "Requirement already satisfied: pyee==12.0.0 in /usr/local/lib/python3.10/dist-packages (from playwright<2.0,>=1.30->llama-index-readers-web) (12.0.0)\n",
      "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.55.3) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.55.3) (2.23.4)\n",
      "Requirement already satisfied: XlsxWriter>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from python-pptx<2.0.0,>=1.0.2->docling) (3.2.0)\n",
      "Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (7.34.0)\n",
      "Requirement already satisfied: jsonpickle>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (4.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->llama-index-readers-web) (3.4.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
      "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.10/dist-packages (from selenium<5.0.0,>=4.17.2->llama-index-readers-web) (0.27.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.10/dist-packages (from selenium<5.0.0,>=4.17.2->llama-index-readers-web) (0.11.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (4.46.3)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.5.2)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from yfinance<0.3.0,>=0.2.36->llama-index-tools-yahoo-finance) (0.0.11)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from yfinance<0.3.0,>=0.2.36->llama-index-tools-yahoo-finance) (4.3.6)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.10/dist-packages (from yfinance<0.3.0,>=0.2.36->llama-index-tools-yahoo-finance) (2.4.6)\n",
      "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.10/dist-packages (from yfinance<0.3.0,>=0.2.36->llama-index-tools-yahoo-finance) (3.17.8)\n",
      "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from yfinance<0.3.0,>=0.2.36->llama-index-tools-yahoo-finance) (1.1)\n",
      "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.10/dist-packages (from feedparser>=5.2.1->newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web) (1.0.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (4.9)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance<0.3.0,>=0.2.36->llama-index-tools-yahoo-finance) (0.5.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.4.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (0.19.2)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (4.4.2)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (0.7.5)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (5.7.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (3.0.48)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (4.9.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.6.1->docling) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.6.1->docling) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.6.1->docling) (0.22.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.10/dist-packages (from tldextract>=2.0.1->newspaper3k<0.3.0,>=0.2.8->llama-index-readers-web) (2.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.4.5)\n",
      "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium<5.0.0,>=4.17.2->llama-index-readers-web) (2.4.0)\n",
      "Requirement already satisfied: outcome in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium<5.0.0,>=4.17.2->llama-index-readers-web) (1.3.0.post0)\n",
      "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.10/dist-packages (from trio-websocket~=0.9->selenium<5.0.0,>=4.17.2->llama-index-readers-web) (1.2.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.3->llama-index) (1.0.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium<5.0.0,>=4.17.2->llama-index-readers-web) (1.7.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.3->llama-index) (3.23.1)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (4.1.1)\n",
      "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr<2.0,>=1.7->docling) (2.36.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr<2.0,>=1.7->docling) (2024.9.20)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr<2.0,>=1.7->docling) (0.4)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.5.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.4->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (1.62.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (3.2.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (0.2.13)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (0.6.1)\n"
     ]
    }
   ],
   "source": [
    "# If we're in colab, use userdata to get the OPENAI_API_KEY\n",
    "import os\n",
    "from rich import print\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    print(\"Colab detected - setting up environment\")\n",
    "    os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
    "    %pip install llama-index \\\n",
    "        \"openai==1.55.3\" \\\n",
    "        \"httpx==0.27.2\" \\\n",
    "        llama-index-readers-web \\\n",
    "        thefuzz \\\n",
    "        gradio \\\n",
    "        chromadb \\\n",
    "        llama-index-embeddings-huggingface \\\n",
    "        llama-index-vector-stores-chroma \\\n",
    "        llama-index-retrievers-bm25 \\\n",
    "        llama-index-llms-gemini \\\n",
    "        docling \\\n",
    "        llama-index-readers-docling \\\n",
    "        llama-index-node-parser-docling \\\n",
    "        llama-index-utils-workflow \\\n",
    "        llama-index-tools-yahoo-finance \\\n",
    "        llama-index-tools-code-interpreter\n",
    "\n",
    "except:\n",
    "    print(\"Not in colab - using local environment variables.\")\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv(\"../.env\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4NLFvzSBSknc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "# Create data directory if it doesn't exist\n",
    "data_dir = \"data\"\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "# Download the PDF file\n",
    "pdf_url = \"https://arxiv.org/pdf/2407.21783\"\n",
    "pdf_path = os.path.join(data_dir, \"2407.21783.pdf\")\n",
    "\n",
    "if not os.path.exists(pdf_path):\n",
    "    response = requests.get(pdf_url)\n",
    "    with open(pdf_path, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    print(f\"Downloaded PDF to {pdf_path}\")\n",
    "else:\n",
    "    print(f\"PDF already exists at {pdf_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3gvSKvLoSknc"
   },
   "source": [
    "The first thing we need to do is to load the data.\n",
    "For general documents like PDFs, LlamaIndex provides a nice abstraction known as a `SimpleDirectoryReader` that can load data from a directory.\n",
    "In the cell below, we use it to load the data from the `data` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KVZAcaI6Sknc"
   },
   "outputs": [],
   "source": [
    "from llama_index.core.readers import SimpleDirectoryReader\n",
    "documents = SimpleDirectoryReader(data_dir).load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XkdP0hMeSknc"
   },
   "source": [
    "Let's take a look at the first document.\n",
    "Most prominently, we get the text of the document.\n",
    "By default, we also get a lot of useful information, like the page number file name, file path, type, size, etc.\n",
    "When we load lots of documents, this type of information becomes important to keep track of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SO4aJEekSknc"
   },
   "outputs": [],
   "source": [
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bBh7G_awSknc"
   },
   "source": [
    "Now that we've loaded the data, we need to vectorize it.\n",
    "We will use a combination of an embedding model and a vector database to store the vectors.\n",
    "In the cell below, we use a HuggingFace embedding model to embed the documents.\n",
    "We also use torch to determine the device to use for the embedding model (`mps` for Mac GPUs, `cuda` for Nvidia GPUs, and `cpu` otherwise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9gigBaqxSknc"
   },
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from torch.backends.mps import is_available as is_mps_available\n",
    "from torch.cuda import is_available as is_cuda_available\n",
    "\n",
    "if is_mps_available():\n",
    "    device = \"mps\"\n",
    "elif is_cuda_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xl_ClchW_p0S"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-large-en-v1.5\", device=device)\n",
    "index = VectorStoreIndex.from_documents(documents, embed_model=embed_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6EsKqIzLSknd"
   },
   "source": [
    "Finally, let's set up our RAG query engine.\n",
    "If we want to perform simple question-answering, we can use the `as_query_engine` method.\n",
    "If we want to perform chat with history, we can use the `as_chat_engine` method.\n",
    "We can see both below 👇.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E92mhz3JSknd"
   },
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import Settings\n",
    "llm = OpenAI(model=\"gpt-4o-mini\")\n",
    "Settings.llm = llm # set gpt-4o-mini as the default llm\n",
    "\n",
    "query_engine = index.as_query_engine(llm=llm)\n",
    "chat_engine = index.as_chat_engine(llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pa2KA1HpSknd"
   },
   "source": [
    "Let's see how the query enine works.\n",
    "We start by passing it a question, then it uses the retriever to find the most relevant documents.\n",
    "Finally, it uses the LLM to answer the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h2xkghnLSknd"
   },
   "outputs": [],
   "source": [
    "response = query_engine.query(\"How many new Llama models models are mentioned in the paper?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-PILhFaISknd"
   },
   "source": [
    "Below we see the response text.\n",
    "But there's also some additional information that we can access, including the source nodes.\n",
    "These are the nodes that the retriever used to answer the question.\n",
    "We can see that the retriever found several nodes that are relevant to the question, then the LLM used at least one of them to answer the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TVgOR5n4Sknd"
   },
   "outputs": [],
   "source": [
    "print(response.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jV5owP0gSknd"
   },
   "source": [
    "Taking a look at the first source node, we can see that it is a node that contains part of the document that is relevant to the question.\n",
    "It also contains the `score`, which is the similarity between the question and the node.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ltNvoLTSknd"
   },
   "outputs": [],
   "source": [
    "print(response.source_nodes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7hwtCT5xSknd"
   },
   "source": [
    "Now let's see if our chat enigine comes up with the same answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z-r2RDmSSknd"
   },
   "outputs": [],
   "source": [
    "chat_response = chat_engine.chat(\"How many new Llama models models are mentioned in the paper?\")\n",
    "print(chat_response.response)\n",
    "print(chat_response.source_nodes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F2DDP6MVSknd"
   },
   "source": [
    "# Data ingestion\n",
    "\n",
    "Data often comes in many different formats.\n",
    "It may come in the form of a PDF, a web page, a code file, etc.\n",
    "We may need some specific processing pipelines to extract the text from these documents, split them correctly, and vectorize them.\n",
    "\n",
    "Luckily, LlamaIndex (and other libraries) provide lots of built-in and add-on tools to help you ingest almost any data type.\n",
    "Instead of loading a PDF, let's load a web page instead.\n",
    "We will use one of the classes provided by [`llama-index-readers-web`](https://llamahub.ai/l/readers/llama-index-readers-web?from=readers) to load data from a web page.\n",
    "\n",
    "In this section, we will:\n",
    "- Load a web page as Markdown\n",
    "- Split it into chunks following the structured format of the Markdown\n",
    "- Embed the chunks\n",
    "- Store the chunks in a vector database\n",
    "- Create a query engine from the vector database and use it to answer a question\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ki0pXIkESknd"
   },
   "outputs": [],
   "source": [
    "from llama_index.readers.web import SimpleWebPageReader\n",
    "from llama_index.core.node_parser import MarkdownNodeParser\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "import chromadb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4--fMgbISknd"
   },
   "outputs": [],
   "source": [
    "web_docs = SimpleWebPageReader(html_to_text=True).load_data(['https://en.wikipedia.org/wiki/Wikipedia'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eOyCH114Sknd"
   },
   "outputs": [],
   "source": [
    "wikipedia_collection = chromadb.EphemeralClient().create_collection(\"wikipedia\", get_or_create=True)\n",
    "wikipedia_vector_store = ChromaVectorStore(wikipedia_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X8bK1uM6Sknd"
   },
   "outputs": [],
   "source": [
    "wikipedia_pipeline = IngestionPipeline(\n",
    "    transformations=[\n",
    "        MarkdownNodeParser.from_defaults(),\n",
    "        embed_model,\n",
    "    ],\n",
    "    vector_store=wikipedia_vector_store\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4h5T-6XvSknd"
   },
   "outputs": [],
   "source": [
    "wikipedia_nodes = wikipedia_pipeline.run(documents=web_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "84J6VTm7Sknd"
   },
   "outputs": [],
   "source": [
    "wikipedia_index = VectorStoreIndex.from_vector_store(wikipedia_vector_store, embed_model=embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dZmbiqRASkne"
   },
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"gpt-4o-mini\")\n",
    "query_engine = wikipedia_index.as_query_engine(llm=llm)\n",
    "response = query_engine.query(\"How many languages there exactly? Quote the exact text as well.\")\n",
    "print(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nhmbOFN7Skne"
   },
   "outputs": [],
   "source": [
    "# Use fuzzywuzzy to find the closest match in the source text\n",
    "from thefuzz import fuzz, process\n",
    "# Get the top matching line of text from the source_text_quote\n",
    "top_match, match_score = process.extractOne(response.response, response.source_nodes[0].text.splitlines(), scorer=fuzz.ratio)\n",
    "assert top_match in response.source_nodes[0].text\n",
    "print(f\"Quote from source: '{top_match}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PHGDGGFlSkne"
   },
   "source": [
    "## OCR\n",
    "\n",
    "There are times where the PDF is not in a format that can be easily read into text.\n",
    "In these cases, we will need to use optical character recognition (OCR) to convert the images to text.\n",
    "There are many libraries and cloud services that can do this, but for this example, we will use the `docling` library since our example document is a PDF.\n",
    "We will then ingest the text into LlamaIndex and use it to answer a question.\n",
    "\n",
    "![](https://ds4sd.github.io/docling/assets/docling_processing.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P68tiprfSkne"
   },
   "outputs": [],
   "source": [
    "from llama_index.readers.docling import DoclingReader\n",
    "from llama_index.node_parser.docling import DoclingNodeParser\n",
    "from llama_index.core.schema import Document\n",
    "from llama_index.core import StorageContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eFaWheMaSkne"
   },
   "outputs": [],
   "source": [
    "reader = DoclingReader(export_type=DoclingReader.ExportType.JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KND4BUZWSkne"
   },
   "outputs": [],
   "source": [
    "docling_docs = reader.load_data(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JrOfzdI5Skne"
   },
   "outputs": [],
   "source": [
    "len(docling_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DeFDyOo-Skne"
   },
   "outputs": [],
   "source": [
    "# We need to set the text template to \"{content}\" because the default is \"{metadata}\\n\\n{content}\",\n",
    "# and LlamaIndex will try to embed the metadata as well. The metadata is not useful at serach time.\n",
    "docling_docs[0].text_template\n",
    "docling_docs[0].text_template = \"{content}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tc7dOcD0Skne"
   },
   "outputs": [],
   "source": [
    "docling_node_parser = DoclingNodeParser()\n",
    "docling_nodes = docling_node_parser.get_nodes_from_documents(docling_docs)\n",
    "len(docling_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d50bB0DDSkne"
   },
   "outputs": [],
   "source": [
    "docling_nodes[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bMDuIrf-Skne"
   },
   "outputs": [],
   "source": [
    "index = VectorStoreIndex(nodes=docling_nodes, embed_model=embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z28dKbV5Skne"
   },
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(llm=llm)\n",
    "response = query_engine.query(\"How many new Llama models are mentioned in the paper?\")\n",
    "print(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nGmXNiAJSkne"
   },
   "outputs": [],
   "source": [
    "print(response.source_nodes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_CzGwrDSknf"
   },
   "source": [
    "# Data splitting\n",
    "\n",
    "Many times, it's impractical to embed the entire document, and expensive to feed the entire document to the LLM.\n",
    "Instead, we can split the document into chunks, embed the chunks, and use a retrieval method to find the most relevant chunks.\n",
    "There are naïve methods that split texts into chunks of a specific length with some overlap;\n",
    "there are methods that use the structure of the document to split it into sections (e.g. sections, figures, tables);\n",
    "and there are more advanced methods that use semantic similarity to group the text into chunks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPuC9cHXSknf"
   },
   "source": [
    "Since the OCR'd text is just one very long Markdown string, we need to split it into chunks.\n",
    "One nice way to do that is use the inherent structure of Markdown to split it into sections.\n",
    "We do that here with LlamaIndex's `MarkdownNodeParser`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r1el-zVlSknf"
   },
   "outputs": [],
   "source": [
    "docling_md_docs = DoclingReader(export_type=DoclingReader.ExportType.MARKDOWN).load_data(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aHnNO23NSknf"
   },
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import MarkdownNodeParser\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XRIz5vjWSknf"
   },
   "outputs": [],
   "source": [
    "md_nodes = MarkdownNodeParser.from_defaults().get_nodes_from_documents(documents=docling_md_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6oKS4vKjSknf"
   },
   "outputs": [],
   "source": [
    "len(md_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tZ7mX3szSknf"
   },
   "outputs": [],
   "source": [
    "display(Markdown(md_nodes[9].text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CiUS4VUcSknf"
   },
   "outputs": [],
   "source": [
    "md_index = VectorStoreIndex(nodes=md_nodes, embed_model=embed_model)\n",
    "md_query_engine = md_index.as_query_engine(llm=llm)\n",
    "response = md_query_engine.query(\"How many llama3 models are there?\")\n",
    "print(response.response)\n",
    "print(response.source_nodes[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1bqHvJwNSknf"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0pYXwOwESknf"
   },
   "source": [
    "# Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ScMHQmreSknf"
   },
   "source": [
    "## Starting simple: bm25\n",
    "\n",
    "BM25 is a simple retrieval method that uses the BM25 algorithm to score the relevance of each document to the query.\n",
    "The BM25 algorithm is a probabilistic retrieval model that uses the term frequency and inverse document frequency of the query terms to score the relevance of each document.\n",
    "You should be familiar with the basic idea of tf-idf from your NLP class - you can think of BM25 as a generalization of tf-idf that takes into account more factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GsVYpkm7Sknf"
   },
   "outputs": [],
   "source": [
    "from llama_index.retrievers.bm25 import BM25Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SYVD5yxsSknf"
   },
   "outputs": [],
   "source": [
    "bm25 = BM25Retriever.from_defaults(nodes=md_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FodffobpSknf"
   },
   "outputs": [],
   "source": [
    "for node in bm25.retrieve(\"How many llama3 models are there?\"):\n",
    "    print(f\"Score: {node.score:.4f}\\nText:\\n{node.node.text[:500]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3PfJ0dvASknf"
   },
   "source": [
    "## Dense retrieval (vector search)\n",
    "\n",
    "BM25 is a simple and fast method that depends on word matching.\n",
    "But if we want to do more complex retrieval, we can use dense retrieval.\n",
    "We represent both our query and documents as vectors and use a similarity metric to find the most relevant documents.\n",
    "This is what's been going on under the hood in the previous examples using `VectorStoreIndex`.\n",
    "\n",
    "Since most of the mechanics are taken care for us under the hood, let's examine what goes on under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oiGBWq0WSknf"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "izNn-ogYSknf"
   },
   "outputs": [],
   "source": [
    "sample_documents = [\n",
    "    \"My favorite type of dog is a golden retriever.\",\n",
    "    \"I like to eat pizza with my friends.\",\n",
    "    \"I like to go to the gym in the morning.\",\n",
    "    \"I like to play basketball with my friends.\",\n",
    "]\n",
    "\n",
    "embeddings = np.array(embed_model.get_text_embedding_batch(sample_documents))\n",
    "\n",
    "query = \"What do I like to do with friends?\"\n",
    "query_embedding = np.array(embed_model.get_text_embedding(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uy13YGwTSknf"
   },
   "outputs": [],
   "source": [
    "cosine_similarity(query_embedding.reshape(1, -1), embeddings).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RgevUYhbSknf"
   },
   "source": [
    "Once we have a `VectorStoreIndex`, we can use the `as_retriever` method to get a retriever object.\n",
    "This uses dense retrieval under the hood, since it already has an embedding model as a part of the class.\n",
    "Here, we use the `similarity_top_k` parameter to limit the number of results to 2 and show the cosine similarity score along with the beginning of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7jqORG2_Skng"
   },
   "outputs": [],
   "source": [
    "query = \"How many llama3 models are there?\"\n",
    "top_results = md_index.as_retriever(similarity_top_k=2).retrieve(query)\n",
    "for result in top_results:\n",
    "    print(f\"Score: {result.score:.4f}\\nText:\\n{result.node.text[:500]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tzc6xqr-Skng"
   },
   "source": [
    "Let's compare bm25 with dense retrieval using %%timeit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QZ36whtOSkng"
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "bm25.retrieve(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qTx7BTsJSkng"
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "md_index.as_retriever(similarity_top_k=2).retrieve(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_yuOMu1gSkng"
   },
   "source": [
    "We can see that bm25 is much faster!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dvIyEn7fSkng"
   },
   "source": [
    "## Hybrid search: query rewriting and reciprocal ranking\n",
    "\n",
    "Sometimes, you may want several methods of searching over your data, then combining the results.\n",
    "This is known as hybrid search.\n",
    "\n",
    "Haveing multiple retrievers may not mean having separate objects - we may just have multiple queries.\n",
    "In this example, we'll use an LLM to rewrite our query into multiple queries, then use a dense retriever to find the most relevant documents.\n",
    "Finally, we'll use reciprocal ranking to re-rank the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hoart7IgSkng"
   },
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers import QueryFusionRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M06EPCt6Skng"
   },
   "outputs": [],
   "source": [
    "dense_retriever = md_index.as_retriever(similarity_top_k=5)\n",
    "hybrid_retriever = QueryFusionRetriever(\n",
    "    [dense_retriever],\n",
    "    num_queries=3,\n",
    "    use_async=False,\n",
    "    mode='reciprocal_rerank',\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rkJ7rMEbSkng"
   },
   "outputs": [],
   "source": [
    "results = hybrid_retriever.retrieve(\"How many llama3 models are there?\")\n",
    "for result in results:\n",
    "    print(f\"Score: {result.score:.4f}\\nText:\\n{result.node.text[:500]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uy9bwCPISkng"
   },
   "source": [
    "# Reranking\n",
    "\n",
    "Often, retrieval only gives us a good first pass at finding relevant documents.\n",
    "We can use re-ranking to improve the results.\n",
    "There are several re-ranking methods, but in this case we'll use a cross-encoder to re-rank the results.\n",
    "The simplest way to rerank is to use a `node_postprocessor` as we construct our query engine or chat engine.\n",
    "Here, we'll use the `SentenceTransformerRerank` node postprocessor to re-rank the top 20 results from the dense retriever down to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zbF7D_K5Skng"
   },
   "outputs": [],
   "source": [
    "from llama_index.core.postprocessor import SentenceTransformerRerank\n",
    "md_query_engine = md_index.as_query_engine(llm=llm, node_postprocessors=[\n",
    "    SentenceTransformerRerank(top_n=5)\n",
    "], retriever_top_k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zs-skomBSkng"
   },
   "outputs": [],
   "source": [
    "response = md_query_engine.query(\"How many llama3 models are there?\")\n",
    "print(response.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tyINIav_Skng"
   },
   "source": [
    "This is also a good opportunity to introduce workflows.\n",
    "Workflows are a lower-level method for organizing tasks that can be chained together.\n",
    "We'll see how to mimic the `md_query_engine` we made above using a workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IK9tKfhvSkng"
   },
   "outputs": [],
   "source": [
    "from llama_index.core.schema import NodeWithScore\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.core.workflow import (\n",
    "    Workflow,\n",
    "    Context,\n",
    "    step,\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    Event\n",
    ")\n",
    "from typing import List\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WN5IDB10Skng"
   },
   "source": [
    "Let's walk throught the code below step by step.\n",
    "First, we define the events that will be passed between the steps.\n",
    "This includes a retrieval result, a re-ranking result, and a prompt for the LLM.\n",
    "The start and stop are already taken care of for us by `StartEvent` and `StopEvent`.\n",
    "\n",
    "Next, we define our `RAGWithReRank` workflow.\n",
    "We initialize it with an index and LLM, which we will use for retrieval and answering and the cross-encoder for re-ranking.\n",
    "We also define exactly what to do for each step of the workflow.\n",
    "It knows what to do because of the `@step` decorator and the types annotations of each method.\n",
    "\n",
    "Finally, we can run the workflow with a query.\n",
    "The workflow will automatically handle passing the events between the steps, so we don't have to worry about that.\n",
    "We can observe that the results are just what we expect as we saw from the previous examples.\n",
    "One advantage of this method is that it's much more flexible - you can include arbitrary code, loops, conditionals, etc.\n",
    "\n",
    "For more detailed documentation on workflows, see [here](https://docs.llamaindex.ai/en/stable/understanding/workflows/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pqh69BEvSkng"
   },
   "outputs": [],
   "source": [
    "# Define the events that will be passed between the steps\n",
    "class RetrievalResult(Event):\n",
    "    results: List[NodeWithScore]\n",
    "\n",
    "class ReRankResult(Event):\n",
    "    results: List[NodeWithScore]\n",
    "\n",
    "class RagPrompt(Event):\n",
    "    prompt: str\n",
    "\n",
    "# Define the workflow\n",
    "class RAGWithReRank(Workflow):\n",
    "    # Initialize the workflow with an index and LLM\n",
    "    def __init__(self, index: VectorStoreIndex = md_index, llm: OpenAI = OpenAI(model=\"gpt-4o-mini\")):\n",
    "        super().__init__(timeout=10, verbose=False)\n",
    "        self.index = index\n",
    "        self.llm = llm\n",
    "        self.reranker = SentenceTransformerRerank(top_n=5)\n",
    "\n",
    "    # The start method is called when the workflow is run.\n",
    "    # This is the first step of the workflow that takes in a query and returns a retrieval result.\n",
    "    # Since we want to use a course retriever, we use a top k of 20.\n",
    "    @step\n",
    "    async def start(self, ctx: Context, ev: StartEvent) -> RetrievalResult:\n",
    "        query = ev.query\n",
    "        await ctx.set('query', query)\n",
    "        results = self.index.as_retriever(similarity_top_k=20).retrieve(query)\n",
    "        return RetrievalResult(results=results)\n",
    "\n",
    "    # This step takes the retrieval results and re-ranks them.\n",
    "    # Notice that the similarity top k is set to 5, so we only keep the top 5 results.\n",
    "    # This is smaller than the retrieval step since this is about refining a smaller number of results.\n",
    "    @step\n",
    "    async def rerank(self, ctx: Context, ev: RetrievalResult) -> ReRankResult:\n",
    "        results = ev.results\n",
    "        query = await ctx.get('query')\n",
    "        reranked = self.reranker.postprocess_nodes(nodes=results, query_str=query)\n",
    "        return ReRankResult(results=reranked)\n",
    "\n",
    "    # This step creates a prompt for the LLM.\n",
    "    # It does this by joining the re-ranked results into a single string and formatting it with the query.\n",
    "    @step\n",
    "    async def create_prompt(self, ctx: Context, ev: ReRankResult) -> RagPrompt:\n",
    "        reranked_results = ev.results\n",
    "        await ctx.set('reranked_results', reranked_results)\n",
    "        query = await ctx.get('query')\n",
    "        reranked_str = '\\n\\n'.join(i.text for i in reranked_results)\n",
    "        prompt = f\"\"\"\\\n",
    "Here is some relevant context:\n",
    "--------------------------------\n",
    "{reranked_str}\n",
    "--------------------------------\n",
    "Based on the above information and not prior knowledge, please answer the question.\n",
    "Question:\n",
    "{query}\n",
    "\"\"\"\n",
    "        return RagPrompt(prompt=prompt)\n",
    "\n",
    "    # This step takes the prompt and uses the LLM to answer the question.\n",
    "    # It also takes the re-ranked results and attaches them to the response in case we want to see the nodes.\n",
    "    @step\n",
    "    async def answer(self, ctx: Context, ev: RagPrompt) -> StopEvent:\n",
    "        prompt = ev.prompt\n",
    "        ranked_results = await ctx.get('reranked_results')\n",
    "        messages = [\n",
    "            ChatMessage.from_str(prompt)\n",
    "        ]\n",
    "        answer = await self.llm.achat(messages)\n",
    "        result = {\n",
    "            \"response\": answer,\n",
    "            \"source_nodes\": ranked_results\n",
    "        }\n",
    "        return StopEvent(result=result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J5nY4IRWSkng"
   },
   "outputs": [],
   "source": [
    "rag = RAGWithReRank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D2alnqQ4Skng"
   },
   "outputs": [],
   "source": [
    "response = await rag.run(query=\"How many llama3 models are there?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hExIxazpSkng"
   },
   "outputs": [],
   "source": [
    "response.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NShulZTPSkng"
   },
   "outputs": [],
   "source": [
    "from llama_index.utils.workflow import draw_all_possible_flows\n",
    "from IPython.core.display import HTML, display\n",
    "draw_all_possible_flows(RAGWithReRank, filename=\"flow.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h3rveXvaSknh"
   },
   "source": [
    "# Exercise: Chat with PDF (30 minutes)\n",
    "\n",
    "Your goal in this exercise is to create a Gradio interface for a question-answering system.\n",
    "Your application should:\n",
    "- Use the query engine created above to answer questions about the uploaded PDF\n",
    "- Display the question and answer in the UI. If using QueryEngine, use a question and answer format. If using ChatEngine, use a chat format.\n",
    "\n",
    "If you need a challenge:\n",
    "- Look at the LlamaIndex docs and add something new to the pipeline, such as [`HyDEQueryTransform`](https://docs.llamaindex.ai/en/stable/examples/query_transformations/HyDEQueryTransformDemo/)\n",
    "- Use the `gr.File` component to allow the user to upload ANY pdf and ask question about it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DU-i_1YlSknh"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QGIBl3H0Sknh"
   },
   "source": [
    "# Agents\n",
    "\n",
    "LLMs on their own have limited capabilities to perform tasks.\n",
    "One way to augment that is to give them tools they can use.\n",
    "These tools allow them to perform actions in the real world, such as searching the web or updating a database.\n",
    "In this section, we'll build up an understanding for how agents work under the hood and how to use them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9EdEb0fPSknh"
   },
   "source": [
    "## Function calling\n",
    "\n",
    "LLMs are fine tuned to call functions with parameters based on the prompt.\n",
    "This means you can provide information about one ore more functions you want to call and have the LLM decide which one to call.\n",
    "This is powerful tool when working with LLMs because it can provide a lot of external data and skills not available to the LLM itself.\n",
    "\n",
    "Let's go through a simple function calling example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0PgLUzkGSknh"
   },
   "outputs": [],
   "source": [
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.llms import ChatMessage\n",
    "import numpy as np\n",
    "from rich import print\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_0TM8z6wSknh"
   },
   "source": [
    "In the cell below, we define a function that rolls a number of dice and returns the results.\n",
    "LlamaIndex provides a `FunctionTool` class that makes it easy to convert a function into a tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bsOEF4sYSknh"
   },
   "outputs": [],
   "source": [
    "def roll_dice(num_dice:int) -> str:\n",
    "    \"\"\"\n",
    "    Rolls a number of dice and returns the results.\n",
    "\n",
    "    Args:\n",
    "        num_dice: The number of dice to roll\n",
    "\n",
    "    Returns:\n",
    "        str: The results of the dice roll (comma separated if multiple dice are rolled)\n",
    "    \"\"\"\n",
    "    return ', '.join(str(np.random.randint(1, 6)) for _ in range(num_dice))\n",
    "\n",
    "roll_dice_tool = FunctionTool.from_defaults(fn=roll_dice, description=\"Useful when you need to roll dice.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OkywNXPVSknh"
   },
   "source": [
    "Let's ask our LLM to roll 5 dice and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iDzdsUBVSknh"
   },
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"gpt-4o-mini\")\n",
    "messages = [\n",
    "    ChatMessage.from_str(\"Roll 5 dice\")\n",
    "]\n",
    "response = llm.chat_with_tools(tools=[roll_dice_tool], messages=messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6WIftLQRSknh"
   },
   "source": [
    "It doesn't actually call the function yet - it just says which function to call and which arguments to pass to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "soZBOHldSknh"
   },
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0GMn1XbrSknh"
   },
   "source": [
    "Let's parse the response to get the function call and arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ei2UwNidSknh"
   },
   "outputs": [],
   "source": [
    "function_call = response.raw.choices[0].message.tool_calls[0].function\n",
    "print(function_call)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O6bccAYWSknh"
   },
   "source": [
    "Finally, let's call the function with the arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iij9WPPcSknh"
   },
   "outputs": [],
   "source": [
    "tool_output = roll_dice_tool.call(**json.loads(function_call.arguments))\n",
    "print(tool_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bBAWQ3DUSknh"
   },
   "source": [
    "Great! Now we have a basic idea of how function calling works under the hood.\n",
    "Agents use function calling to call tools, but generally use them in loops combined with reasoning steps to accomplish complex tasks.\n",
    "Next, we'll see how to use LlamaIndex's implementation of agents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GOcSDvmcSknh"
   },
   "source": [
    "## Intro to Llama index agents: Financial Data Agent\n",
    "\n",
    "We've seen how to use function calling with an LLM, but it was kind of difficult to go from the LLM response to the function call.\n",
    "We didn't even close the loop and pass the tool call result back to the LLM.\n",
    "LlamaIndex's `FunctionCallingAgent` and `ReActAgent` classes make this easier.\n",
    "Let's go through an example of using the `FunctionCallingAgent` to perform a more complex tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FYfXUgxiSknh"
   },
   "outputs": [],
   "source": [
    "from llama_index.core.agent import ReActAgent, FunctionCallingAgent\n",
    "from llama_index.agent.openai import OpenAIAgent\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.tools.yahoo_finance import YahooFinanceToolSpec\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from yfinance import download as yf_download\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4n-LPKVhSknh"
   },
   "source": [
    "It's really useful to be able to define your own tools.\n",
    "Luckliy, LlamaIndex makes this easy with the `FunctionTool` class.\n",
    "Here, we'll define a tool that gets stock data from Yahoo Finance and returns it as a markdown table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z1A8hREDRLE-"
   },
   "outputs": [],
   "source": [
    "# def get_todays_date() -> str:\n",
    "#   \"\"\"\n",
    "#   Gets today's date\n",
    "#   \"\"\"\n",
    "\n",
    "# today_tool = FunctionTool.from_defaults(fn=get_todays_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QdL7uoUaSkni"
   },
   "outputs": [],
   "source": [
    "def get_stock_data(ticker:str, start_date:str, end_date:str) -> str:\n",
    "    \"\"\"\n",
    "    Gets stock data using yfinance. All dates should be in YYYY-MM-DD format.\n",
    "\n",
    "    Args:\n",
    "        ticker: The ticker symbol of the stock to get data for\n",
    "        start_date: The start date of the data to get\n",
    "        end_date: The end date of the data to get\n",
    "\n",
    "    Returns:\n",
    "        str: A markdown table of the stock data\n",
    "    \"\"\"\n",
    "    df = yf_download(ticker, start=start_date, end=end_date)\n",
    "    return df.to_markdown()\n",
    "\n",
    "get_stock_data_tool = FunctionTool.from_defaults(fn=get_stock_data, description=\"Useful when you want to pull trended data about a stock.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gdp91kuOSkni"
   },
   "source": [
    "Now, we can pass this tool to an agent to have it answer questions about stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eHbwLURvSkni"
   },
   "outputs": [],
   "source": [
    "agent = FunctionCallingAgent.from_tools(tools=[get_stock_data_tool], llm=OpenAI(model=\"gpt-4o-mini\"), verbose=True)\n",
    "response = agent.chat(f\"What was TSLA's high and low over the last 7 days?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7xrOMrJbSkni"
   },
   "outputs": [],
   "source": [
    "print(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Etfggj2LQ4lL"
   },
   "outputs": [],
   "source": [
    "agent = FunctionCallingAgent.from_tools(tools=[get_stock_data_tool], llm=OpenAI(model=\"gpt-4o-mini\"), verbose=True)\n",
    "response = agent.chat(f\"What was TSLA's high and low over the last 7 days? Today's date is {datetime.today}\")\n",
    "print(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tKYBnLfoQ_Or"
   },
   "outputs": [],
   "source": [
    "agent = ReActAgent.from_tools(tools=[get_stock_data_tool], llm=OpenAI(model=\"gpt-4o-mini\"), verbose=True)\n",
    "response = agent.chat(f\"What was TSLA's high and low over the last 7 days? Today's date is {datetime.today}\")\n",
    "print(response.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1duk-GmESkni"
   },
   "source": [
    "### Check for understanding\n",
    "\n",
    "Is there anything strange about the response to this question above?\n",
    "What do you think we could do to fix it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D2TkTqNfSkni"
   },
   "source": [
    "## Using pre-packaged tools\n",
    "\n",
    "LlamaIndex has a number of tools that are pre-defined and can be installed.\n",
    "In this case, we will use the `YahooFinanceToolSpec` to get additional information about a stock beyond just the trended data.\n",
    "We will also add our `get_stock_data_tool` to the list of tools, since getting trended data is not a part of the `YahooFinanceToolSpec`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g2yzZQ8LSkni"
   },
   "outputs": [],
   "source": [
    "yfinance_tools = YahooFinanceToolSpec().to_tool_list()\n",
    "yfinance_tools.append(get_stock_data_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I5L2x8H1Skni"
   },
   "outputs": [],
   "source": [
    "agent = FunctionCallingAgent.from_tools(tools=yfinance_tools, llm=OpenAI(model=\"gpt-4o-mini\"), verbose=True)\n",
    "response = agent.chat(f\"What was TSLA's high and low over the last 7 days? Today's date is {datetime.now().strftime('%Y-%m-%d')}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u4xtFE11Skni"
   },
   "outputs": [],
   "source": [
    "response = agent.chat(\"What does TSLA make?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JtIYYC7kSkni"
   },
   "source": [
    "## Demo 2: Agentic RAG\n",
    "\n",
    "In the previous examples of RAG, we had a single retriever that retrieved documents from a single index.\n",
    "But what if we have multiple indices we want to use?\n",
    "We can use an agent to decide which index to use and then retrieve from that index.\n",
    "One great way to do this is to turn the indices we made previously into tools.\n",
    "We'll make an agent that can answer questions about the llama3 paper OR the Wikipedia page we ingested earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t6rFDyiASkni"
   },
   "outputs": [],
   "source": [
    "from llama_index.core.tools import RetrieverTool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mzQK1_e1Skni"
   },
   "source": [
    "Let's create a tool for each of our indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0z3jBm-USkni"
   },
   "outputs": [],
   "source": [
    "wikipedia_tool = RetrieverTool.from_defaults(\n",
    "    retriever=wikipedia_index.as_retriever(),\n",
    "    name=\"wikipedia_retriever\",\n",
    "    description=\"Useful when you need information about the Wikipedia organization.\"\n",
    ")\n",
    "llama_tool = RetrieverTool.from_defaults(\n",
    "    retriever=md_index.as_retriever(),\n",
    "    name=\"llama_retriever\",\n",
    "    description=\"Useful when you need information about the llama3 paper.\"\n",
    ")\n",
    "\n",
    "retriever_tools = [wikipedia_tool, llama_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IPqSwjHMSkni"
   },
   "source": [
    "Now, we can pass these tools to an agent to have it answer questions about the Wikipedia page or the llama3 paper.\n",
    "This time, instead of using the `FunctionCallingAgent`, we'll use the `OpenAIAgent`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "brLrAocHSkni"
   },
   "outputs": [],
   "source": [
    "rag_agent = OpenAIAgent.from_tools(tools=retriever_tools, llm=OpenAI(model=\"gpt-4o-mini\"), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T7KFHzkKSkni"
   },
   "outputs": [],
   "source": [
    "rag_agent.query(\"When was Wikipedia founded?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bXDhU_f5Skni"
   },
   "outputs": [],
   "source": [
    "rag_agent.query(\"How did llama3 8b perform on MMLU?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fGR7GunYSkni"
   },
   "source": [
    "## Demo 3: Code interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_b1b4S29Skni"
   },
   "outputs": [],
   "source": [
    "from llama_index.tools.code_interpreter import CodeInterpreterToolSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ofxtzTQnSkni"
   },
   "outputs": [],
   "source": [
    "code_tools = CodeInterpreterToolSpec().to_tool_list()\n",
    "system_prompt = \"\"\"\\\n",
    "You are a helpful assistant that can answer questions by executing python code. \\\n",
    "Always make sure to print the results to StdOut.\n",
    "\"\"\"\n",
    "code_agent = OpenAIAgent.from_tools(tools=code_tools, llm=OpenAI(model=\"gpt-4o-mini\"), verbose=True, system_prompt=system_prompt)\n",
    "code_agent.query(\"What is the square root of 9936.3981?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L6CVJTPRSkni"
   },
   "source": [
    "### Check for understanding\n",
    "\n",
    "What are some possible downsides and security concerns of using a code interpreter tool?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ni2Sh2xiSkni"
   },
   "source": [
    "# Exercise: Build your own agent\n",
    "\n",
    "The goal of this exercise is to build your own agent.\n",
    "\n",
    "\n",
    "## Planning (15 minutes)\n",
    "\n",
    "Your goal over the next 15 minutes is to answer the following questions:\n",
    "- What is the goal of the agent? What task (or tasks) will it accomplish?\n",
    "- What tools will it need to use to accomplish its goal?\n",
    "- How will it use the tools to accomplish its goal?\n",
    "- What is the modality of the agent? (for example, conversational, workflow, code writing, etc.)\n",
    "\n",
    "If you need some inspiration, here are some ideas places you can go to learn about external tools:\n",
    "- [Llam Index tools on LlamaHub](https://llamahub.ai/?tab=tools)\n",
    "- [This repo with free APIs](https://github.com/public-api-lists/public-api-lists) (look for ones w/o auth since we don't have a ton of time for setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L1sOVp_USkni"
   },
   "source": [
    "#### YOUR PLAN HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eric's Idea\n",
    "\n",
    "Use\n",
    "\n",
    "\n",
    "Agent: Stock Trading Assistant\n",
    "\n",
    "\n",
    "1. Get the top 10 NASDAQ most active (pre-market) tickers and also 5 minutes after the market opens.\n",
    "    1a. Premarket\n",
    "    1b. After market opens today\n",
    "2. Get past 1 years of daily data from yahoo finance.\n",
    "    2a. Average for 40 days Compute if the trend is possitive or negative.\n",
    "3. Get the % Change from the day before market close. \n",
    "4. Get the number of active shares issue.\n",
    "5. Get the number of volume issue.\n",
    "6. Get the number of price low and high from pre-market\n",
    "7. Get the number of price low and high from yesterday\n",
    "8. Get the number of price low and high from the last 5 minutes\n",
    "9. Compute all the standard deviations.\n",
    "10. Get the ticker with highest possitive %Change, the highest volume and number of shares, the highest standard deviation and has a positive trend for the last 1 year.\n",
    "11. Send the result via whatsapp text.\n",
    "\n",
    "\n",
    "You may use some of this tools if necessary:\n",
    "from llama_index.core.agent import ReActAgent, FunctionCallingAgent\n",
    "from llama_index.agent.openai import OpenAIAgent\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.tools.yahoo_finance import YahooFinanceToolSpec\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from yfinance import download as yf_download\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agent: Stock Trading Assistant\n",
    "The agent will analyze stock market data in real-time and send insights via WhatsApp.\n",
    "\n",
    "Steps and Tasks\n",
    "Step 1: Get Top 10 NASDAQ Most Active Tickers\n",
    "1a: Premarket\n",
    "Retrieve the top 10 most active NASDAQ tickers before the market opens.\n",
    "\n",
    "1b: After Market Opens\n",
    "Retrieve the top 10 most active NASDAQ tickers 5 minutes after the market opens.\n",
    "\n",
    "Step 2: Fetch 1 Year of Historical Data\n",
    "Daily Data\n",
    "Retrieve the past year’s daily stock price data for the tickers obtained in Step 1 using Yahoo Finance.\n",
    "\n",
    "40-Day Moving Average Trend\n",
    "Compute the 40-day moving average for each ticker and determine if the trend is positive (upward) or negative (downward).\n",
    "\n",
    "Step 3: Calculate % Change\n",
    "Day-Over-Day % Change\n",
    "Calculate the percentage change in the stock price compared to the previous day’s closing price.\n",
    "Step 4: Retrieve Number of Active Shares\n",
    "Get the total number of shares issued for each ticker.\n",
    "Step 5: Retrieve Trading Volume\n",
    "Retrieve the trading volume for each ticker.\n",
    "Step 6: Get Premarket Price Highs and Lows\n",
    "Identify the highest and lowest prices for each ticker during the premarket session.\n",
    "Step 7: Get Yesterday’s Price Highs and Lows\n",
    "Retrieve the highest and lowest prices for each ticker during the previous trading day.\n",
    "Step 8: Get Last 5 Minutes’ Price Highs and Lows\n",
    "Identify the highest and lowest prices for each ticker in the last 5 minutes of trading activity.\n",
    "Step 9: Compute Standard Deviations (Real-Time)\n",
    "Calculate the standard deviations of price values for each ticker based on:\n",
    "Premarket highs and lows (Step 6).\n",
    "Yesterday’s highs and lows (Step 7).\n",
    "Last 5 minutes’ highs and lows (Step 8).\n",
    "This step provides a measure of real-time price volatility.\n",
    "\n",
    "Step 10: Identify the Best Ticker\n",
    "Determine the stock ticker that meets all the following criteria:\n",
    "Highest Positive % Change (from Step 3).\n",
    "Highest Volume (from Step 5).\n",
    "Highest Number of Shares Issued (from Step 4).\n",
    "Highest Standard Deviation (from Step 9).\n",
    "Positive 40-Day Trend (from Step 2).\n",
    "Step 11: Send the Result via WhatsApp\n",
    "Send a message summarizing the best ticker and relevant metrics (e.g., % change, volume, shares, trend, and standard deviation) using a WhatsApp API.\n",
    "Tools & Libraries\n",
    "LlamaIndex\n",
    "\n",
    "Use ReActAgent or FunctionCallingAgent for step automation and task execution.\n",
    "Leverage the YahooFinanceToolSpec for real-time stock data retrieval.\n",
    "yfinance\n",
    "\n",
    "Fetch premarket, historical, and real-time price data.\n",
    "datetime\n",
    "\n",
    "Manage time-based filtering for data (e.g., last 5 minutes).\n",
    "WhatsApp API (e.g., Twilio)\n",
    "\n",
    "Send notifications with the final results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brew install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "# Create a directed graph to represent the workflow of the Stock Trading Assistant agent\n",
    "workflow = Digraph(format='png', graph_attr={'rankdir': 'LR', 'fontsize': '12', 'fontname': 'Arial'})\n",
    "workflow.attr('node', shape='box', fontsize='10', fontname='Arial')\n",
    "\n",
    "# Step 1: Get NASDAQ Most Active Tickers\n",
    "workflow.node(\"Step 1\", \"Step 1: Get NASDAQ Most Active Tickers\\n1a. Premarket\\n1b. 5 Minutes After Market Opens\")\n",
    "\n",
    "# Step 2: Fetch Historical Data\n",
    "workflow.node(\"Step 2\", \"Step 2: Fetch 1-Year Historical Data\\n- 40-Day Moving Average Trend\")\n",
    "\n",
    "# Step 3: Calculate % Change\n",
    "workflow.node(\"Step 3\", \"Step 3: Calculate Day-Over-Day % Change\")\n",
    "\n",
    "# Step 4: Retrieve Active Shares\n",
    "workflow.node(\"Step 4\", \"Step 4: Retrieve Number of Active Shares\")\n",
    "\n",
    "# Step 5: Retrieve Volume\n",
    "workflow.node(\"Step 5\", \"Step 5: Retrieve Trading Volume\")\n",
    "\n",
    "# Step 6: Premarket Highs and Lows\n",
    "workflow.node(\"Step 6\", \"Step 6: Get Premarket Price Highs and Lows\")\n",
    "\n",
    "# Step 7: Yesterday's Highs and Lows\n",
    "workflow.node(\"Step 7\", \"Step 7: Get Yesterday's Price Highs and Lows\")\n",
    "\n",
    "# Step 8: Last 5 Minutes Highs and Lows\n",
    "workflow.node(\"Step 8\", \"Step 8: Get Last 5 Minutes' Price Highs and Lows\")\n",
    "\n",
    "# Step 9: Compute Standard Deviations\n",
    "workflow.node(\"Step 9\", \"Step 9: Compute Standard Deviations\\n- Premarket, Yesterday, Last 5 Minutes\")\n",
    "\n",
    "# Step 10: Identify Best Ticker\n",
    "workflow.node(\"Step 10\", \"Step 10: Identify Best Ticker\\n- Highest % Change\\n- Highest Volume\\n- Highest Shares\\n- Highest Std. Dev.\\n- Positive Trend\")\n",
    "\n",
    "# Step 11: Send Result via WhatsApp\n",
    "workflow.node(\"Step 11\", \"Step 11: Send Result via WhatsApp\")\n",
    "\n",
    "# Connect the nodes to represent the workflow\n",
    "workflow.edges([\n",
    "    (\"Step 1\", \"Step 2\"),\n",
    "    (\"Step 2\", \"Step 3\"),\n",
    "    (\"Step 3\", \"Step 4\"),\n",
    "    (\"Step 4\", \"Step 5\"),\n",
    "    (\"Step 5\", \"Step 6\"),\n",
    "    (\"Step 6\", \"Step 7\"),\n",
    "    (\"Step 7\", \"Step 8\"),\n",
    "    (\"Step 8\", \"Step 9\"),\n",
    "    (\"Step 9\", \"Step 10\"),\n",
    "    (\"Step 10\", \"Step 11\")\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the diagram as a PNG\n",
    "output_path = \"./stock_trading_assistant_workflow\"\n",
    "workflow.render(output_path, format='png', cleanup=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "98JbAONvSknj"
   },
   "source": [
    "## Backend building (30 minutes)\n",
    "\n",
    "Use LlamaIndex agents to build out your agent.\n",
    "Your goal over the next 30 minutes is to:\n",
    "- Create (or import) any tools you need to accomplish your goal.\n",
    "- Create your agent using one of the agent classes provided by LlamaIndex.\n",
    "- Create 2-3 test cases and check your agent against them to see if it produces the desired output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uncotzkJSknj"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip show llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import ReActAgent, FunctionCallingAgent\n",
    "from llama_index.agent.openai import OpenAIAgent\n",
    "from llama_index.core.tools import FunctionTool\n",
    "\n",
    "import yfinance as yf\n",
    "\n",
    "from llama_index.tools.yahoo_finance import YahooFinanceToolSpec\n",
    "\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "import os\n",
    "from google.colab import userdata\n",
    "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
    "\n",
    "\n",
    "\n",
    "# Function to send a message via WhatsApp using an API (e.g., Twilio)\n",
    "def send_whatsapp_message(message, recipient_number):\n",
    "    # Twilio or equivalent API details\n",
    "    API_URL = \"https://api.example.com/send-message\"\n",
    "    API_TOKEN = \"your_api_token\"\n",
    "    \n",
    "    payload = {\n",
    "        \"to\": recipient_number,\n",
    "        \"message\": message,\n",
    "    }\n",
    "    headers = {\"Authorization\": f\"Bearer {API_TOKEN}\"}\n",
    "    response = requests.post(API_URL, json=payload, headers=headers)\n",
    "    return response.status_code\n",
    "\n",
    "# Step 1: Get NASDAQ Most Active Tickers\n",
    "def get_most_active_tickers(period=\"1d\"):\n",
    "    nasdaq_data = yf.download(\"^IXIC\", period=period, interval=\"1m\")\n",
    "    return nasdaq_data.index[:10]  # Simulated: Replace with actual most active tickers logic\n",
    "\n",
    "# Step 2: Fetch 1-Year Historical Data\n",
    "def fetch_historical_data(tickers):\n",
    "    data = {}\n",
    "    for ticker in tickers:\n",
    "        stock_data = yf.download(ticker, period=\"1y\")\n",
    "        data[ticker] = stock_data\n",
    "    return data\n",
    "\n",
    "def compute_40_day_trend(data):\n",
    "    trends = {}\n",
    "    for ticker, df in data.items():\n",
    "        df['40D_MA'] = df['Close'].rolling(window=40).mean()\n",
    "        trends[ticker] = \"Positive\" if df['40D_MA'].iloc[-1] > df['40D_MA'].iloc[0] else \"Negative\"\n",
    "    return trends\n",
    "\n",
    "# Step 3: Calculate % Change\n",
    "def calculate_percent_change(data):\n",
    "    percent_changes = {}\n",
    "    for ticker, df in data.items():\n",
    "        yesterday_close = df['Close'].iloc[-2]\n",
    "        today_open = df['Open'].iloc[-1]\n",
    "        percent_changes[ticker] = ((today_open - yesterday_close) / yesterday_close) * 100\n",
    "    return percent_changes\n",
    "\n",
    "# Step 4 & 5: Get Active Shares and Volume\n",
    "def get_active_shares_and_volume(tickers):\n",
    "    results = {}\n",
    "    for ticker in tickers:\n",
    "        info = yf.Ticker(ticker).info\n",
    "        results[ticker] = {\n",
    "            \"shares_outstanding\": info.get(\"sharesOutstanding\", 0),\n",
    "            \"volume\": info.get(\"volume\", 0),\n",
    "        }\n",
    "    return results\n",
    "\n",
    "# Step 6, 7 & 8: Price Highs and Lows\n",
    "def get_price_highs_and_lows(tickers, timeframe):\n",
    "    results = {}\n",
    "    for ticker in tickers:\n",
    "        stock_data = yf.download(ticker, period=timeframe)\n",
    "        results[ticker] = {\n",
    "            \"high\": stock_data['High'].max(),\n",
    "            \"low\": stock_data['Low'].min(),\n",
    "        }\n",
    "    return results\n",
    "\n",
    "# Step 9: Compute Standard Deviations\n",
    "def compute_standard_deviations(price_data):\n",
    "    std_devs = {}\n",
    "    for ticker, data in price_data.items():\n",
    "        std_devs[ticker] = np.std([data[\"high\"], data[\"low\"]])\n",
    "    return std_devs\n",
    "\n",
    "# Step 10: Identify Best Ticker\n",
    "def identify_best_ticker(percent_changes, volumes, active_shares, std_devs, trends):\n",
    "    best_ticker = None\n",
    "    highest_score = -1\n",
    "\n",
    "    for ticker in percent_changes.keys():\n",
    "        if trends[ticker] == \"Positive\":\n",
    "            score = (\n",
    "                percent_changes[ticker] +\n",
    "                volumes[ticker][\"volume\"] +\n",
    "                active_shares[ticker][\"shares_outstanding\"] +\n",
    "                std_devs[ticker]\n",
    "            )\n",
    "            if score > highest_score:\n",
    "                highest_score = score\n",
    "                best_ticker = ticker\n",
    "    return best_ticker\n",
    "\n",
    "# Step 11: Send Results via WhatsApp\n",
    "def notify_result(best_ticker, percent_changes, volumes, active_shares, trends, recipient_number):\n",
    "    message = (\n",
    "        f\"Best Ticker: {best_ticker}\\n\"\n",
    "        f\"% Change: {percent_changes[best_ticker]:.2f}%\\n\"\n",
    "        f\"Volume: {volumes[best_ticker]['volume']}\\n\"\n",
    "        f\"Shares Outstanding: {active_shares[best_ticker]['shares_outstanding']}\\n\"\n",
    "        f\"Trend: {trends[best_ticker]}\"\n",
    "    )\n",
    "    send_whatsapp_message(message, recipient_number)\n",
    "\n",
    "# Main Execution Flow\n",
    "def stock_trading_assistant(recipient_number):\n",
    "    # Step 1\n",
    "    tickers = get_most_active_tickers()\n",
    "    \n",
    "    # Step 2\n",
    "    historical_data = fetch_historical_data(tickers)\n",
    "    trends = compute_40_day_trend(historical_data)\n",
    "    \n",
    "    # Step 3\n",
    "    percent_changes = calculate_percent_change(historical_data)\n",
    "    \n",
    "    # Step 4 & 5\n",
    "    volumes_and_shares = get_active_shares_and_volume(tickers)\n",
    "    \n",
    "    # Step 6, 7, 8\n",
    "    premarket_data = get_price_highs_and_lows(tickers, \"1d\")\n",
    "    yesterday_data = get_price_highs_and_lows(tickers, \"5d\")\n",
    "    last_5_min_data = get_price_highs_and_lows(tickers, \"1m\")\n",
    "    \n",
    "    # Step 9\n",
    "    std_devs = compute_standard_deviations({\n",
    "        ticker: {\n",
    "            \"high\": premarket_data[ticker][\"high\"],\n",
    "            \"low\": last_5_min_data[ticker][\"low\"]\n",
    "        }\n",
    "        for ticker in tickers\n",
    "    })\n",
    "    \n",
    "    # Step 10\n",
    "    best_ticker = identify_best_ticker(\n",
    "        percent_changes,\n",
    "        volumes_and_shares,\n",
    "        volumes_and_shares,\n",
    "        std_devs,\n",
    "        trends\n",
    "    )\n",
    "    \n",
    "    # Step 11\n",
    "    notify_result(best_ticker, percent_changes, volumes_and_shares, volumes_and_shares, trends, recipient_number)\n",
    "\n",
    "# Run the agent\n",
    "recipient = \"+1234567890\"  # Replace with the actual recipient number\n",
    "stock_trading_assistant(recipient)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338
    },
    "executionInfo": {
     "elapsed": 2013,
     "status": "ok",
     "timestamp": 1733616120250,
     "user": {
      "displayName": "Eric Michel",
      "userId": "07676971985746424800"
     },
     "user_tz": 480
    },
    "id": "k60izURqkI4Q",
    "outputId": "3c0fd3ab-084a-4ea8-b685-8a042dd3efbf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Start Date: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Start Date: \u001b[1;36m2023\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m09\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">End Date: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">08</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "End Date: \u001b[1;36m2024\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m08\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Price        Adj Close       Close        High         Low        Open  \\\n",
       "Ticker            AAPL        AAPL        AAPL        AAPL        AAPL   \n",
       "Date                                                                     \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">239.589996</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">239.589996</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">240.789993</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">237.160004</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">237.270004</span>   \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">242.649994</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">242.649994</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">242.759995</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">238.899994</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">239.809998</span>   \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">243.009995</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">243.009995</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">244.110001</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">241.250000</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">242.869995</span>   \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">05</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">243.039993</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">243.039993</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">244.539993</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">242.130005</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">243.990005</span>   \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">242.839996</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">242.839996</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">244.630005</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">242.080002</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">242.910004</span>   \n",
       "\n",
       "Price         Volume  \n",
       "Ticker          AAPL  \n",
       "Date                  \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">48137100</span>  \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">38861000</span>  \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">44383900</span>  \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">05</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">40033900</span>  \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36852100</span>  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Price        Adj Close       Close        High         Low        Open  \\\n",
       "Ticker            AAPL        AAPL        AAPL        AAPL        AAPL   \n",
       "Date                                                                     \n",
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m02\u001b[0m  \u001b[1;36m239.589996\u001b[0m  \u001b[1;36m239.589996\u001b[0m  \u001b[1;36m240.789993\u001b[0m  \u001b[1;36m237.160004\u001b[0m  \u001b[1;36m237.270004\u001b[0m   \n",
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m03\u001b[0m  \u001b[1;36m242.649994\u001b[0m  \u001b[1;36m242.649994\u001b[0m  \u001b[1;36m242.759995\u001b[0m  \u001b[1;36m238.899994\u001b[0m  \u001b[1;36m239.809998\u001b[0m   \n",
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m04\u001b[0m  \u001b[1;36m243.009995\u001b[0m  \u001b[1;36m243.009995\u001b[0m  \u001b[1;36m244.110001\u001b[0m  \u001b[1;36m241.250000\u001b[0m  \u001b[1;36m242.869995\u001b[0m   \n",
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m05\u001b[0m  \u001b[1;36m243.039993\u001b[0m  \u001b[1;36m243.039993\u001b[0m  \u001b[1;36m244.539993\u001b[0m  \u001b[1;36m242.130005\u001b[0m  \u001b[1;36m243.990005\u001b[0m   \n",
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m06\u001b[0m  \u001b[1;36m242.839996\u001b[0m  \u001b[1;36m242.839996\u001b[0m  \u001b[1;36m244.630005\u001b[0m  \u001b[1;36m242.080002\u001b[0m  \u001b[1;36m242.910004\u001b[0m   \n",
       "\n",
       "Price         Volume  \n",
       "Ticker          AAPL  \n",
       "Date                  \n",
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m02\u001b[0m  \u001b[1;36m48137100\u001b[0m  \n",
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m03\u001b[0m  \u001b[1;36m38861000\u001b[0m  \n",
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m04\u001b[0m  \u001b[1;36m44383900\u001b[0m  \n",
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m05\u001b[0m  \u001b[1;36m40033900\u001b[0m  \n",
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m06\u001b[0m  \u001b[1;36m36852100\u001b[0m  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Example of date manipulation\n",
    "start_date = datetime.now() - timedelta(days=365)\n",
    "end_date = datetime.now()\n",
    "\n",
    "print(\"Start Date:\", start_date.strftime('%Y-%m-%d'))\n",
    "print(\"End Date:\", end_date.strftime('%Y-%m-%d'))\n",
    "\n",
    "# Ensure yfinance handles these dates\n",
    "ticker = \"AAPL\"\n",
    "stock_data = yf.download(ticker, start=start_date.strftime('%Y-%m-%d'), end=end_date.strftime('%Y-%m-%d'))\n",
    "print(stock_data.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 731,
     "status": "ok",
     "timestamp": 1733618285917,
     "user": {
      "displayName": "Eric Michel",
      "userId": "07676971985746424800"
     },
     "user_tz": 480
    },
    "id": "qbXDeMBOpl_s",
    "outputId": "4d1bf46b-487b-4417-e7bc-640b43ff92ef"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "tickers = get_most_active_tickers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1733618288388,
     "user": {
      "displayName": "Eric Michel",
      "userId": "07676971985746424800"
     },
     "user_tz": 480
    },
    "id": "SdX058tlpqbS",
    "outputId": "6311d924-ebc8-4005-882e-0c438b4a2c76"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Price                         Adj Close         Close          High  \\\n",
       "Ticker                            ^IXIC         ^IXIC         ^IXIC   \n",
       "Datetime                                                              \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:30:00</span>+<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">00:00</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19737.169922</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19737.169922</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19749.605469</span>   \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:31:00</span>+<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">00:00</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19741.789062</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19741.789062</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19757.300781</span>   \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:32:00</span>+<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">00:00</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19750.146484</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19750.146484</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19753.339844</span>   \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:33:00</span>+<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">00:00</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19766.419922</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19766.419922</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19766.419922</span>   \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:34:00</span>+<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">00:00</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19767.306641</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19767.306641</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19770.794922</span>   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                 <span style=\"color: #808000; text-decoration-color: #808000\">...</span>           <span style=\"color: #808000; text-decoration-color: #808000\">...</span>           <span style=\"color: #808000; text-decoration-color: #808000\">...</span>   \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">20:55:00</span>+<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">00:00</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19858.599609</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19858.599609</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19858.832031</span>   \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">20:56:00</span>+<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">00:00</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19858.898438</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19858.898438</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19858.898438</span>   \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">20:57:00</span>+<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">00:00</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19858.304688</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19858.304688</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19859.369141</span>   \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">20:58:00</span>+<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">00:00</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19856.341797</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19856.341797</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19860.593750</span>   \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">20:59:00</span>+<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">00:00</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19854.685547</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19854.685547</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19861.406250</span>   \n",
       "\n",
       "Price                               Low          Open    Volume  \n",
       "Ticker                            ^IXIC         ^IXIC     ^IXIC  \n",
       "Datetime                                                         \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:30:00</span>+<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">00:00</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19735.029297</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19749.333984</span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>  \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:31:00</span>+<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">00:00</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19741.789062</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19743.939453</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">51354161</span>  \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:32:00</span>+<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">00:00</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19741.773438</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19741.773438</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">37316648</span>  \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:33:00</span>+<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">00:00</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19753.582031</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19756.626953</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">35532966</span>  \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:34:00</span>+<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">00:00</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19766.128906</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19769.099609</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33629523</span>  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                 <span style=\"color: #808000; text-decoration-color: #808000\">...</span>           <span style=\"color: #808000; text-decoration-color: #808000\">...</span>       <span style=\"color: #808000; text-decoration-color: #808000\">...</span>  \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">20:55:00</span>+<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">00:00</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19856.210938</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19856.210938</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19884000</span>  \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">20:56:00</span>+<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">00:00</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19853.410156</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19858.603516</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32001000</span>  \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">20:57:00</span>+<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">00:00</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19856.140625</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19857.101562</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">54960000</span>  \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">20:58:00</span>+<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">00:00</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19855.343750</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19858.902344</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17769000</span>  \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">20:59:00</span>+<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">00:00</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19854.685547</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19854.845703</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">35179000</span>  \n",
       "\n",
       "<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">388</span> rows x <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> columns<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Price                         Adj Close         Close          High  \\\n",
       "Ticker                            ^IXIC         ^IXIC         ^IXIC   \n",
       "Datetime                                                              \n",
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m14:30:00\u001b[0m+\u001b[1;92m00:00\u001b[0m  \u001b[1;36m19737.169922\u001b[0m  \u001b[1;36m19737.169922\u001b[0m  \u001b[1;36m19749.605469\u001b[0m   \n",
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m14:31:00\u001b[0m+\u001b[1;92m00:00\u001b[0m  \u001b[1;36m19741.789062\u001b[0m  \u001b[1;36m19741.789062\u001b[0m  \u001b[1;36m19757.300781\u001b[0m   \n",
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m14:32:00\u001b[0m+\u001b[1;92m00:00\u001b[0m  \u001b[1;36m19750.146484\u001b[0m  \u001b[1;36m19750.146484\u001b[0m  \u001b[1;36m19753.339844\u001b[0m   \n",
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m14:33:00\u001b[0m+\u001b[1;92m00:00\u001b[0m  \u001b[1;36m19766.419922\u001b[0m  \u001b[1;36m19766.419922\u001b[0m  \u001b[1;36m19766.419922\u001b[0m   \n",
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m14:34:00\u001b[0m+\u001b[1;92m00:00\u001b[0m  \u001b[1;36m19767.306641\u001b[0m  \u001b[1;36m19767.306641\u001b[0m  \u001b[1;36m19770.794922\u001b[0m   \n",
       "\u001b[33m...\u001b[0m                                 \u001b[33m...\u001b[0m           \u001b[33m...\u001b[0m           \u001b[33m...\u001b[0m   \n",
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m20:55:00\u001b[0m+\u001b[1;92m00:00\u001b[0m  \u001b[1;36m19858.599609\u001b[0m  \u001b[1;36m19858.599609\u001b[0m  \u001b[1;36m19858.832031\u001b[0m   \n",
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m20:56:00\u001b[0m+\u001b[1;92m00:00\u001b[0m  \u001b[1;36m19858.898438\u001b[0m  \u001b[1;36m19858.898438\u001b[0m  \u001b[1;36m19858.898438\u001b[0m   \n",
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m20:57:00\u001b[0m+\u001b[1;92m00:00\u001b[0m  \u001b[1;36m19858.304688\u001b[0m  \u001b[1;36m19858.304688\u001b[0m  \u001b[1;36m19859.369141\u001b[0m   \n",
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m20:58:00\u001b[0m+\u001b[1;92m00:00\u001b[0m  \u001b[1;36m19856.341797\u001b[0m  \u001b[1;36m19856.341797\u001b[0m  \u001b[1;36m19860.593750\u001b[0m   \n",
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m20:59:00\u001b[0m+\u001b[1;92m00:00\u001b[0m  \u001b[1;36m19854.685547\u001b[0m  \u001b[1;36m19854.685547\u001b[0m  \u001b[1;36m19861.406250\u001b[0m   \n",
       "\n",
       "Price                               Low          Open    Volume  \n",
       "Ticker                            ^IXIC         ^IXIC     ^IXIC  \n",
       "Datetime                                                         \n",
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m14:30:00\u001b[0m+\u001b[1;92m00:00\u001b[0m  \u001b[1;36m19735.029297\u001b[0m  \u001b[1;36m19749.333984\u001b[0m         \u001b[1;36m0\u001b[0m  \n",
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m14:31:00\u001b[0m+\u001b[1;92m00:00\u001b[0m  \u001b[1;36m19741.789062\u001b[0m  \u001b[1;36m19743.939453\u001b[0m  \u001b[1;36m51354161\u001b[0m  \n",
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m14:32:00\u001b[0m+\u001b[1;92m00:00\u001b[0m  \u001b[1;36m19741.773438\u001b[0m  \u001b[1;36m19741.773438\u001b[0m  \u001b[1;36m37316648\u001b[0m  \n",
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m14:33:00\u001b[0m+\u001b[1;92m00:00\u001b[0m  \u001b[1;36m19753.582031\u001b[0m  \u001b[1;36m19756.626953\u001b[0m  \u001b[1;36m35532966\u001b[0m  \n",
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m14:34:00\u001b[0m+\u001b[1;92m00:00\u001b[0m  \u001b[1;36m19766.128906\u001b[0m  \u001b[1;36m19769.099609\u001b[0m  \u001b[1;36m33629523\u001b[0m  \n",
       "\u001b[33m...\u001b[0m                                 \u001b[33m...\u001b[0m           \u001b[33m...\u001b[0m       \u001b[33m...\u001b[0m  \n",
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m20:55:00\u001b[0m+\u001b[1;92m00:00\u001b[0m  \u001b[1;36m19856.210938\u001b[0m  \u001b[1;36m19856.210938\u001b[0m  \u001b[1;36m19884000\u001b[0m  \n",
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m20:56:00\u001b[0m+\u001b[1;92m00:00\u001b[0m  \u001b[1;36m19853.410156\u001b[0m  \u001b[1;36m19858.603516\u001b[0m  \u001b[1;36m32001000\u001b[0m  \n",
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m20:57:00\u001b[0m+\u001b[1;92m00:00\u001b[0m  \u001b[1;36m19856.140625\u001b[0m  \u001b[1;36m19857.101562\u001b[0m  \u001b[1;36m54960000\u001b[0m  \n",
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m20:58:00\u001b[0m+\u001b[1;92m00:00\u001b[0m  \u001b[1;36m19855.343750\u001b[0m  \u001b[1;36m19858.902344\u001b[0m  \u001b[1;36m17769000\u001b[0m  \n",
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m20:59:00\u001b[0m+\u001b[1;92m00:00\u001b[0m  \u001b[1;36m19854.685547\u001b[0m  \u001b[1;36m19854.845703\u001b[0m  \u001b[1;36m35179000\u001b[0m  \n",
       "\n",
       "\u001b[1m[\u001b[0m\u001b[1;36m388\u001b[0m rows x \u001b[1;36m6\u001b[0m columns\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 499
    },
    "executionInfo": {
     "elapsed": 945,
     "status": "error",
     "timestamp": 1733616169870,
     "user": {
      "displayName": "Eric Michel",
      "userId": "07676971985746424800"
     },
     "user_tz": 480
    },
    "id": "0qHAiRRekLmh",
    "outputId": "33c7d626-ae9c-47b7-e154-3bbc6a48f92a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Error fetching data for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:30:00</span>+<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">00:00</span>: value must be an integer, received <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">class</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">'str'</span><span style=\"font-weight: bold\">&gt;</span> for year\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Error fetching data for \u001b[1;36m2024\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m14:30:00\u001b[0m+\u001b[1;92m00:00\u001b[0m: value must be an integer, received \u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m\u001b[32m'str'\u001b[0m\u001b[1m>\u001b[0m for year\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Error fetching data for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:31:00</span>+<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">00:00</span>: value must be an integer, received <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">class</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">'str'</span><span style=\"font-weight: bold\">&gt;</span> for year\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Error fetching data for \u001b[1;36m2024\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m14:31:00\u001b[0m+\u001b[1;92m00:00\u001b[0m: value must be an integer, received \u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m\u001b[32m'str'\u001b[0m\u001b[1m>\u001b[0m for year\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Error fetching data for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:32:00</span>+<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">00:00</span>: value must be an integer, received <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">class</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">'str'</span><span style=\"font-weight: bold\">&gt;</span> for year\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Error fetching data for \u001b[1;36m2024\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m14:32:00\u001b[0m+\u001b[1;92m00:00\u001b[0m: value must be an integer, received \u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m\u001b[32m'str'\u001b[0m\u001b[1m>\u001b[0m for year\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Error fetching data for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:33:00</span>+<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">00:00</span>: value must be an integer, received <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">class</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">'str'</span><span style=\"font-weight: bold\">&gt;</span> for year\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Error fetching data for \u001b[1;36m2024\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m14:33:00\u001b[0m+\u001b[1;92m00:00\u001b[0m: value must be an integer, received \u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m\u001b[32m'str'\u001b[0m\u001b[1m>\u001b[0m for year\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Error fetching data for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:34:00</span>+<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">00:00</span>: value must be an integer, received <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">class</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">'str'</span><span style=\"font-weight: bold\">&gt;</span> for year\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Error fetching data for \u001b[1;36m2024\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m14:34:00\u001b[0m+\u001b[1;92m00:00\u001b[0m: value must be an integer, received \u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m\u001b[32m'str'\u001b[0m\u001b[1m>\u001b[0m for year\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Error fetching data for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:35:00</span>+<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">00:00</span>: value must be an integer, received <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">class</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">'str'</span><span style=\"font-weight: bold\">&gt;</span> for year\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Error fetching data for \u001b[1;36m2024\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m14:35:00\u001b[0m+\u001b[1;92m00:00\u001b[0m: value must be an integer, received \u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m\u001b[32m'str'\u001b[0m\u001b[1m>\u001b[0m for year\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Error fetching data for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:36:00</span>+<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">00:00</span>: value must be an integer, received <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">class</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">'str'</span><span style=\"font-weight: bold\">&gt;</span> for year\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Error fetching data for \u001b[1;36m2024\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m14:36:00\u001b[0m+\u001b[1;92m00:00\u001b[0m: value must be an integer, received \u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m\u001b[32m'str'\u001b[0m\u001b[1m>\u001b[0m for year\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Error fetching data for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:37:00</span>+<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">00:00</span>: value must be an integer, received <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">class</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">'str'</span><span style=\"font-weight: bold\">&gt;</span> for year\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Error fetching data for \u001b[1;36m2024\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m14:37:00\u001b[0m+\u001b[1;92m00:00\u001b[0m: value must be an integer, received \u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m\u001b[32m'str'\u001b[0m\u001b[1m>\u001b[0m for year\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Error fetching data for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:38:00</span>+<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">00:00</span>: value must be an integer, received <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">class</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">'str'</span><span style=\"font-weight: bold\">&gt;</span> for year\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Error fetching data for \u001b[1;36m2024\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m14:38:00\u001b[0m+\u001b[1;92m00:00\u001b[0m: value must be an integer, received \u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m\u001b[32m'str'\u001b[0m\u001b[1m>\u001b[0m for year\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Error fetching data for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:39:00</span>+<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">00:00</span>: value must be an integer, received <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">class</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">'str'</span><span style=\"font-weight: bold\">&gt;</span> for year\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Error fetching data for \u001b[1;36m2024\u001b[0m-\u001b[1;36m12\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m14:39:00\u001b[0m+\u001b[1;92m00:00\u001b[0m: value must be an integer, received \u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m\u001b[32m'str'\u001b[0m\u001b[1m>\u001b[0m for year\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'Timestamp' object has no attribute 'upper'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-78a99bd4508a>\u001b[0m in \u001b[0;36m<cell line: 44>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# Run the agent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mrecipient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"+1234567890\"\u001b[0m  \u001b[0;31m# Replace with the actual recipient number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mstock_trading_assistant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecipient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-78a99bd4508a>\u001b[0m in \u001b[0;36mstock_trading_assistant\u001b[0;34m(recipient_number)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Step 4 & 5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mvolumes_and_shares\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_active_shares_and_volume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtickers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Step 6, 7, 8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-1f2ab8a75171>\u001b[0m in \u001b[0;36mget_active_shares_and_volume\u001b[0;34m(tickers)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mticker\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtickers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTicker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         results[ticker] = {\n\u001b[1;32m     67\u001b[0m             \u001b[0;34m\"shares_outstanding\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sharesOutstanding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/yfinance/ticker.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ticker, session, proxy)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mTicker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTickerBase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mticker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTicker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_expirations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_underlying\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/yfinance/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ticker, session, proxy)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mTickerBase\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mticker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mticker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mticker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproxy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproxy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Timestamp' object has no attribute 'upper'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Main Execution Flow\n",
    "def stock_trading_assistant(recipient_number):\n",
    "    # Step 1\n",
    "    tickers = get_most_active_tickers()\n",
    "\n",
    "    # Step 2\n",
    "    historical_data = fetch_historical_data(tickers)\n",
    "    trends = compute_40_day_trend(historical_data)\n",
    "\n",
    "    # Step 3\n",
    "    percent_changes = calculate_percent_change(historical_data)\n",
    "\n",
    "    # Step 4 & 5\n",
    "    volumes_and_shares = get_active_shares_and_volume(tickers)\n",
    "\n",
    "    # Step 6, 7, 8\n",
    "    premarket_data = get_price_highs_and_lows(tickers, \"1d\")\n",
    "    yesterday_data = get_price_highs_and_lows(tickers, \"5d\")\n",
    "    last_5_min_data = get_price_highs_and_lows(tickers, \"1m\")\n",
    "\n",
    "    # Step 9\n",
    "    std_devs = compute_standard_deviations({\n",
    "        ticker: {\n",
    "            \"high\": premarket_data[ticker][\"high\"],\n",
    "            \"low\": last_5_min_data[ticker][\"low\"]\n",
    "        }\n",
    "        for ticker in tickers\n",
    "    })\n",
    "\n",
    "    # Step 10\n",
    "    best_ticker = identify_best_ticker(\n",
    "        percent_changes,\n",
    "        volumes_and_shares,\n",
    "        volumes_and_shares,\n",
    "        std_devs,\n",
    "        trends\n",
    "    )\n",
    "\n",
    "    # Step 11\n",
    "    notify_result(best_ticker, percent_changes, volumes_and_shares, volumes_and_shares, trends, recipient_number)\n",
    "\n",
    "# Run the agent\n",
    "recipient = \"+1234567890\"  # Replace with the actual recipient number\n",
    "stock_trading_assistant(recipient)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "88q2aYiZSknj"
   },
   "source": [
    "## Frontend building (15 minutes)\n",
    "\n",
    "Your goal over the next 15 minutes is to:\n",
    "- Use `gradio` to build an interface for your agent.\n",
    "- Test your agent with 2-3 different inputs to ensure it's working as expected.\n",
    "- If you want to use your agent more like an api, check out the [`gradio-client`](https://www.gradio.app/docs/python-client/introduction) library and run your test cases programmatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SmaGcDh4Sknj"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "executionInfo": {
     "elapsed": 9232,
     "status": "ok",
     "timestamp": 1733617635550,
     "user": {
      "displayName": "Eric Michel",
      "userId": "07676971985746424800"
     },
     "user_tz": 480
    },
    "id": "GU_UBko4Sknj",
    "outputId": "a879fb1f-cc90-43d1-952d-4756fcb7acfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "* Running on public URL: https://a24bc09b594794b116.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://a24bc09b594794b116.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Core functions for the Stock Trading Assistant\n",
    "def stock_trading_assistant(recipient_number):\n",
    "    # Step 1: Get the NASDAQ most active tickers (for simplicity, using hardcoded tickers here)\n",
    "    tickers = [\"AAPL\", \"MSFT\", \"TSLA\", \"GOOGL\", \"AMZN\"]  # Replace with dynamic retrieval\n",
    "\n",
    "    # Step 2: Fetch historical data\n",
    "    historical_data = fetch_historical_data(tickers)\n",
    "    trends = compute_40_day_trend(historical_data)\n",
    "\n",
    "    # Step 3: Calculate percentage change\n",
    "    percent_changes = calculate_percent_change(historical_data)\n",
    "\n",
    "    # Step 4 & 5: Get active shares and volume\n",
    "    volumes_and_shares = get_active_shares_and_volume(tickers)\n",
    "\n",
    "    # Step 6, 7, 8: Price highs and lows\n",
    "    premarket_data = get_price_highs_and_lows(tickers, \"1d\")\n",
    "    yesterday_data = get_price_highs_and_lows(tickers, \"5d\")\n",
    "    last_5_min_data = get_price_highs_and_lows(tickers, \"1m\")\n",
    "\n",
    "    # Step 9: Compute standard deviations\n",
    "    std_devs = compute_standard_deviations({\n",
    "        ticker: {\n",
    "            \"high\": premarket_data[ticker][\"high\"],\n",
    "            \"low\": last_5_min_data[ticker][\"low\"]\n",
    "        }\n",
    "        for ticker in tickers\n",
    "    })\n",
    "\n",
    "    # Step 10: Identify the best ticker\n",
    "    best_ticker = identify_best_ticker(\n",
    "        percent_changes,\n",
    "        volumes_and_shares,\n",
    "        volumes_and_shares,\n",
    "        std_devs,\n",
    "        trends\n",
    "    )\n",
    "\n",
    "    # Result message\n",
    "    message = (\n",
    "        f\"Best Ticker: {best_ticker}\\n\"\n",
    "        f\"% Change: {percent_changes[best_ticker]:.2f}%\\n\"\n",
    "        f\"Volume: {volumes_and_shares[best_ticker]['volume']}\\n\"\n",
    "        f\"Shares Outstanding: {volumes_and_shares[best_ticker]['shares_outstanding']}\\n\"\n",
    "        f\"Trend: {trends[best_ticker]}\"\n",
    "    )\n",
    "\n",
    "    return message\n",
    "\n",
    "# Gradio interface\n",
    "def assistant_interface(recipient_number):\n",
    "    # Run the stock trading assistant\n",
    "    result = stock_trading_assistant(recipient_number)\n",
    "    return result\n",
    "\n",
    "# Define Gradio inputs and outputs\n",
    "with gr.Blocks() as interface:\n",
    "    gr.Markdown(\"## Stock Trading Assistant\")\n",
    "\n",
    "    with gr.Row():\n",
    "        recipient_number_input = gr.Textbox(\n",
    "            label=\"Enter Recipient Phone Number\",\n",
    "            placeholder=\"+1234567890\"\n",
    "        )\n",
    "\n",
    "    with gr.Row():\n",
    "        run_button = gr.Button(\"Run Stock Trading Assistant\")\n",
    "\n",
    "    with gr.Row():\n",
    "        result_output = gr.Textbox(label=\"Result\", interactive=False)\n",
    "\n",
    "    run_button.click(assistant_interface, inputs=[recipient_number_input], outputs=[result_output])\n",
    "\n",
    "# Launch Gradio interface\n",
    "interface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install gradio-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gradio_client import Client\n",
    "\n",
    "client = Client(\"http://localhost:7860/\")  # Use the URL from the Gradio app\n",
    "response = client.predict(\"+1234567890\", api_name=\"default\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
