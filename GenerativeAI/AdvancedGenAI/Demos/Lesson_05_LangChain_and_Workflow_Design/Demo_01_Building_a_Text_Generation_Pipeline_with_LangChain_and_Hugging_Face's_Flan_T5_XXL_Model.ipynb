{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# __Please run the provided demo notebook file in Google Colab to explore the hands-on example.__"
      ],
      "metadata": {
        "id": "GLbOMNIisxUq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSNe5dGyCZlq"
      },
      "source": [
        "#**Demo: Building a Text Generation Pipeline with LangChain and Hugging Face's Flan T5 XXL Model**\n",
        "\n",
        "In this demo, you will learn how to create a Langchain HuggingFacePipeline for efficient text generation and dive into the creation of a Langchain chain to craft context-aware responses using a custom template."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GIv4H_3Ce2F"
      },
      "source": [
        "##**Steps to Perform:**\n",
        "1. Install the Required Libraries and Dependencies\n",
        "2. Authenticate the Hugging Face Account and Set the API Key\n",
        "3. Use the Hugging Face Hub to Load the Flan T5 XXL model\n",
        "4. Create a Langchain HuggingFacePipeline for Text Generation\n",
        "5. Build a Chain Using Langchain\n",
        "6. Test and Run the Chain on Few a Questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMiJv-SkCo9e"
      },
      "source": [
        "###**Step 1: Install the Required Libraries and Dependencies**\n",
        "\n",
        "\n",
        "*   Install the necessary libraries, including **Langchain**, **Transformers**, and **Torch**.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Npz_xvrIxm3"
      },
      "outputs": [],
      "source": [
        "!pip install langchain transformers torch accelerate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ip2zy0mDC93N"
      },
      "source": [
        "###**Step 2: Authenticate the Hugging Face Account and Set the API Key**\n",
        "\n",
        "*   Click this link: https://huggingface.co/settings/tokens\n",
        "*   Login or create an account.\n",
        "*   Click on **New token**.\n",
        "*   On the dialog box, give a name and select the role as **write**.\n",
        "*   Copy the access token or API key.\n",
        "*   Replace **Your_HF_Key** with the copied key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_my4ywipYl1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"Your_HF_Key\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veodvSN0Dc7r"
      },
      "source": [
        "###**Step 3: Use the Hugging Face Hub to Load the Flan T5 XXL model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4tjani-Zsd7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain import HuggingFaceHub\n",
        "\n",
        "llm=HuggingFaceHub(repo_id=\"google/flan-t5-xxl\", model_kwargs={\"temperature\":1, \"max_length\":512})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wE90-mP9FHCJ"
      },
      "source": [
        "###**Step 4: Create a Langchain HuggingFacePipeline for Text Generation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4sfC8putZ4NX"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6PN8DGuFSIn"
      },
      "source": [
        "###**Step 5: Build a Chain Using Langchain**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMzZa8lmqF_i"
      },
      "outputs": [],
      "source": [
        "template = \"\"\"Question: {question}\n",
        "\n",
        "Answer: Let's think step by step.\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
        "\n",
        "llm_chain = LLMChain(prompt=prompt, llm=llm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCy0qU74Ff4p"
      },
      "source": [
        "###**Step 6: Test and Run the Chain on Few a Questions**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzJK0rXNqKwA"
      },
      "outputs": [],
      "source": [
        "#Question 1\n",
        "question = \"Explain the concept of black holes in simple terms.\"\n",
        "\n",
        "llm_chain.run(question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3-3arLF-1Ms"
      },
      "outputs": [],
      "source": [
        "#Question 2\n",
        "question = \"What are the main causes of climate change, and how can we address them?\"\n",
        "\n",
        "llm_chain.run(question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdK6ZB2GBMM0"
      },
      "outputs": [],
      "source": [
        "#Question 3\n",
        "question = \"Provide a brief overview of the history of artificial intelligence.\"\n",
        "\n",
        "llm_chain.run(question)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGtdoqadFq-R"
      },
      "source": [
        "##**Conclusion**\n",
        "\n",
        "This sets the stage for your Langchain journey, allowing you to interact with language models seamlessly. In the upcoming demos, we will explore more advanced applications development with Langchain."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}