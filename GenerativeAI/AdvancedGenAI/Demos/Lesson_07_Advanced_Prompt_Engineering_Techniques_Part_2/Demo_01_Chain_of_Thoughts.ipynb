{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "oBl1D-pEjs6I",
   "metadata": {
    "id": "oBl1D-pEjs6I"
   },
   "source": [
    "# __Demo: Chain of Thought Prompting with LangChain and OpenAI__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lvZdkb4YpOHd",
   "metadata": {
    "id": "lvZdkb4YpOHd"
   },
   "source": [
    "## __Steps to Perform:__\n",
    "Step 1: Set up the OpenAI API Key\n",
    "\n",
    "Step 2: Initialize the langchain\n",
    "\n",
    "Step 3: Define Your Template\n",
    "\n",
    "Step 4: Define and Run the Chain of Thought Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Q91iZEcUqMci",
   "metadata": {
    "id": "Q91iZEcUqMci"
   },
   "source": [
    "### __Step 1: Set up the OpenAI API Key__\n",
    "- Import the required libraries and set up the OpenAI API key.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "344be232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/anaconda3/lib/python3.11/site-packages (1.60.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai) (0.8.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.11/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/lib/python3.11/site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/anaconda3/lib/python3.11/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/anaconda3/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n"
     ]
    }
   ],
   "source": [
    "# !pip install --upgrade pip\n",
    "# !pip install --upgrade openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b77ac5df-7119-4777-b0ba-910e5811a852",
   "metadata": {
    "id": "b77ac5df-7119-4777-b0ba-910e5811a852"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# import openai\n",
    "\n",
    "# from langchain.llms import OpenAI\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# from openai import OpenAI\n",
    "\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "# openai.api_key  = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "client = OpenAI(api_key=os.environ['OPENAI_API_KEY'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8CLt67fQq7FE",
   "metadata": {
    "id": "8CLt67fQq7FE"
   },
   "source": [
    "### __Step 2: Initialize the langchain__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "504caddf-3cec-4c96-983f-a73c29bf4223",
   "metadata": {
    "id": "504caddf-3cec-4c96-983f-a73c29bf4223"
   },
   "outputs": [],
   "source": [
    "# Initialize the OpenAI LLM with temperature set to 0 for deterministic output\n",
    "# llm = OpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CZHiudNysyw4",
   "metadata": {
    "id": "CZHiudNysyw4"
   },
   "source": [
    "### __Step 3: Define Your Template__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "417cc372-7a86-48b6-9400-366a4a7e7992",
   "metadata": {
    "id": "417cc372-7a86-48b6-9400-366a4a7e7992",
    "outputId": "854fd4aa-ca28-4c32-9bec-bcba311693d8"
   },
   "outputs": [],
   "source": [
    "# Define a series of prompts using LangChain's PromptTemplate\n",
    "template = \"\"\"\n",
    "{thought_step}\n",
    "\"\"\"\n",
    "\n",
    "# Create a PromptTemplate object\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"thought_step\"])\n",
    "\n",
    "# Initialize an LLMChain to combine the LLM and the prompt template\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sY2lKxE2twjn",
   "metadata": {
    "id": "sY2lKxE2twjn"
   },
   "source": [
    "## __Step 4: Define and Run the Chain of Thought Prompts__\n",
    "Feed each prompt into the llm_chain.run() function and print the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8253ff2d-25f5-4289-a4f1-1f1d2b346381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Imagine you are a detective trying to solve a mystery.\n",
      "Response: Case: The Vanishing Diamond\n",
      "\n",
      "As a seasoned detective, I've seen my fair share of mysteries, but this one was particularly intriguing. The case involved a priceless diamond, known as the \"Star of the East,\" which had vanished from the vault of a renowned billionaire, Mr. Charles Davenport.\n",
      "\n",
      "The vault was located in the basement of Davenport's mansion, a fortress-like structure with state-of-the-art security systems. The diamond was last seen during a party hosted by Davenport. The next morning, it was gone. There were no signs of forced entry, the security system was intact, and the vault was locked.\n",
      "\n",
      "I started my investigation by interviewing the staff and guests. The staff included a butler, a maid, and a security guard. The guests were a mix of socialites, business tycoons, and a few unknown faces. Everyone claimed innocence and seemed equally shocked by the theft.\n",
      "\n",
      "Next, I examined the security footage. The cameras showed the guests enjoying the party, but nothing suspicious. The vault camera, however, was mysteriously offline during the time of the theft.\n",
      "\n",
      "I then inspected the vault. It was a high-tech safe with a biometric lock that could only be opened by Davenport's fingerprint. Inside, I found a small, empty pedestal where the diamond once sat. There were no signs of tampering.\n",
      "\n",
      "The mystery deepened. How could the diamond disappear from a locked vault without triggering any alarms?\n",
      "\n",
      "I decided to dig deeper into the guests' backgrounds. One of them, a young tech entrepreneur named Ethan, had a history of hacking. Could he have hacked the security system and the biometric lock?\n",
      "\n",
      "I confronted Ethan, who admitted to being a hacker but denied any involvement in the theft. He claimed he was at the party to seek investment for his new startup. However, he did mention that he noticed Davenport's nephew, Alex, acting strangely during the party.\n",
      "\n",
      "I turned my attention to Alex. He was a known gambler with a hefty debt. Could he have stolen the diamond to pay off his debts? But how could he bypass the biometric lock?\n",
      "\n",
      "I decided to re-examine the security footage, this time focusing on Alex. I noticed that during the party, Alex had a brief, seemingly casual interaction with Davenport where they shook hands. Could he have used that opportunity to lift his uncle's fingerprint?\n",
      "\n",
      "I confronted Alex with my theory. After a tense standoff, he confessed. He had used a special adhesive on his hand during the handshake to lift his uncle's fingerprint. He then used it to open the vault, took the diamond, and replaced the camera footage with old recordings.\n",
      "\n",
      "The mystery of the vanishing diamond was finally solved. Alex was arrested, and the diamond was recovered from a local pawn shop. Once again, I was reminded that in detective work, every detail matters.\n",
      "--------------------------------------------------\n",
      "Prompt: You arrive at the crime scene and start looking for clues.\n",
      "Response: The crime scene is a small, dimly lit apartment. The air is heavy with the scent of stale cigarettes and something metallic, like blood. The room is in disarray, furniture overturned, papers scattered everywhere. \n",
      "\n",
      "You start by examining the body. The victim, a middle-aged man, is sprawled on the floor, a pool of dried blood around his head. His eyes are wide open, a look of surprise etched on his face. There's a deep gash on his forehead, probably the cause of death. \n",
      "\n",
      "Next, you move to the overturned furniture. A chair is broken, suggesting a struggle. You notice a small, shiny object under the couch. It's a silver locket, the chain broken. Inside, there's a picture of a young woman. \n",
      "\n",
      "You then turn your attention to the scattered papers. Most of them are bills, but one catches your eye. It's a letter, handwritten, the ink smudged in places. It's a threatening letter, warning the victim to stop his investigations or face the consequences. \n",
      "\n",
      "Finally, you notice a small, black notebook on the coffee table. Flipping through it, you find it's filled with notes and observations, like a diary. The last entry, dated the day before the murder, mentions a meeting with a person named 'J'. \n",
      "\n",
      "With these clues in hand, you step back, taking one last look at the crime scene. It's time to start piecing together the puzzle.\n",
      "--------------------------------------------------\n",
      "Prompt: You find a strange object at the crime scene. What is it?\n",
      "Response: A small, intricately carved jade figurine of an unknown creature.\n",
      "--------------------------------------------------\n",
      "Prompt: How does this object relate to the crime?\n",
      "Response: As an AI, I need more specific details to provide an accurate response. What object are you referring to and what crime are you talking about?\n",
      "--------------------------------------------------\n",
      "Prompt: Who do you think is the suspect and why?\n",
      "Response: As an AI, I don't have personal opinions or beliefs. However, I can analyze data and provide information based on that. Please provide more context or details for me to give a more accurate response.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# List of prompts that represent the chain of thought\n",
    "prompts = [\n",
    "    \"Imagine you are a detective trying to solve a mystery.\",\n",
    "    \"You arrive at the crime scene and start looking for clues.\",\n",
    "    \"You find a strange object at the crime scene. What is it?\",\n",
    "    \"How does this object relate to the crime?\",\n",
    "    \"Who do you think is the suspect and why?\"\n",
    "]\n",
    "# Loop through each step in the chain of thought and get responses\n",
    "for step in prompts:\n",
    "    # response = llm_chain.run(thought_step=step)\n",
    "    response = llm.invoke([HumanMessage(content=step)])\n",
    "    print(f\"Prompt: {step}\")\n",
    "    print(f\"Response: {response.content.strip()}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50931ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
