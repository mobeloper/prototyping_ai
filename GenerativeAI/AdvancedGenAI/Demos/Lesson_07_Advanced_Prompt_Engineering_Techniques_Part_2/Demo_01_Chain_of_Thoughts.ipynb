{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CeygmCvBEgwW",
   "metadata": {
    "id": "CeygmCvBEgwW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "oBl1D-pEjs6I",
   "metadata": {
    "id": "oBl1D-pEjs6I"
   },
   "source": [
    "# __Demo: Chain of Thought Prompting with LangChain and OpenAI__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lvZdkb4YpOHd",
   "metadata": {
    "id": "lvZdkb4YpOHd"
   },
   "source": [
    "## __Steps to Perform:__\n",
    "Step 1: Set up the OpenAI API Key\n",
    "\n",
    "Step 2: Initialize the langchain\n",
    "\n",
    "Step 3: Define Your Template\n",
    "\n",
    "Step 4: Define and Run the Chain of Thought Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Q91iZEcUqMci",
   "metadata": {
    "id": "Q91iZEcUqMci"
   },
   "source": [
    "### __Step 1: Set up the OpenAI API Key__\n",
    "- Import the required libraries and set up the OpenAI API key.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b77ac5df-7119-4777-b0ba-910e5811a852",
   "metadata": {
    "id": "b77ac5df-7119-4777-b0ba-910e5811a852"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "#from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "#_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "#openai.api_key  = os.getenv('OPENAI_API_KEY')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8CLt67fQq7FE",
   "metadata": {
    "id": "8CLt67fQq7FE"
   },
   "source": [
    "### __Step 2: Initialize the langchain__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "504caddf-3cec-4c96-983f-a73c29bf4223",
   "metadata": {
    "id": "504caddf-3cec-4c96-983f-a73c29bf4223"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/voc/work/.local/lib/python3.10/site-packages/langchain/llms/openai.py:241: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/voc/work/.local/lib/python3.10/site-packages/langchain/llms/openai.py:898: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize the OpenAI LLM with temperature set to 0 for deterministic output\n",
    "llm = OpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CZHiudNysyw4",
   "metadata": {
    "id": "CZHiudNysyw4"
   },
   "source": [
    "### __Step 3: Define Your Template__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "417cc372-7a86-48b6-9400-366a4a7e7992",
   "metadata": {
    "id": "417cc372-7a86-48b6-9400-366a4a7e7992",
    "outputId": "854fd4aa-ca28-4c32-9bec-bcba311693d8"
   },
   "outputs": [],
   "source": [
    "# Define a series of prompts using LangChain's PromptTemplate\n",
    "template = \"\"\"\n",
    "{thought_step}\n",
    "\"\"\"\n",
    "\n",
    "# Create a PromptTemplate object\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"thought_step\"])\n",
    "\n",
    "# Initialize an LLMChain to combine the LLM and the prompt template\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sY2lKxE2twjn",
   "metadata": {
    "id": "sY2lKxE2twjn"
   },
   "source": [
    "## __Step 4: Define and Run the Chain of Thought Prompts__\n",
    "Feed each prompt into the llm_chain.run() function and print the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83354f75-010b-4122-b8a2-a185ae1f32a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Imagine you are a detective trying to solve a mystery.\n",
      "Response: As a detective, I would start by gathering all the evidence related to the case. This would include interviewing witnesses, collecting physical evidence from the crime scene, and reviewing any surveillance footage that may be available.\n",
      "\n",
      "I would also look into the background of the victim and any potential suspects to see if there are any motives or connections that could help solve the case. Additionally, I would work closely with forensic experts to analyze any DNA or other forensic evidence that may be present.\n",
      "\n",
      "Throughout the investigation, I would keep an open mind and consider all possible leads and theories. I would also work closely with my team and any other law enforcement agencies involved in the case to ensure that we are covering all angles and working together to solve the mystery.\n",
      "\n",
      "Ultimately, my goal as a detective would be to piece together all the evidence and information to uncover the truth behind the mystery and bring justice to the victim and their loved ones.\n",
      "--------------------------------------------------\n",
      "Prompt: You arrive at the crime scene and start looking for clues.\n",
      "Response: You notice a broken window and a trail of footprints leading away from the scene. As you follow the footprints, you come across a discarded glove with a distinct logo on it. You carefully bag it as evidence and continue your search.\n",
      "\n",
      "You also find a piece of torn fabric caught on a nearby fence, which appears to match the fabric of the suspect's clothing described by witnesses. You carefully collect the fabric and mark its location for further analysis.\n",
      "\n",
      "As you continue to search the area, you spot a security camera mounted on a nearby building. You quickly request the footage from the building owner to see if it captured any suspicious activity around the time of the crime.\n",
      "\n",
      "After thoroughly examining the crime scene and collecting all possible evidence, you head back to the station to analyze and process the clues you found. It's time to piece together the puzzle and solve the case.\n",
      "--------------------------------------------------\n",
      "Prompt: You find a strange object at the crime scene. What is it?\n",
      "Response: The strange object found at the crime scene is a small, intricately carved wooden figurine of a mysterious creature with glowing red eyes. It appears to be of ancient origin and emits a faint, eerie energy when touched. Its significance and connection to the crime are unknown, but it definitely adds a layer of mystery to the investigation.\n",
      "--------------------------------------------------\n",
      "Prompt: How does this object relate to the crime?\n",
      "Response: Without knowing what the object is or any context about the crime being referenced, it is impossible to determine how the object relates to the crime. More information would be needed to make that connection.\n",
      "--------------------------------------------------\n",
      "Prompt: Who do you think is the suspect and why?\n",
      "Response: I'm sorry, but I cannot provide an answer to that question as I do not have enough information about the situation or the individuals involved. It is important to gather evidence and information before making any accusations or assumptions about who may be the suspect in a situation.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# List of prompts that represent the chain of thought\n",
    "prompts = [\n",
    "    \"Imagine you are a detective trying to solve a mystery.\",\n",
    "    \"You arrive at the crime scene and start looking for clues.\",\n",
    "    \"You find a strange object at the crime scene. What is it?\",\n",
    "    \"How does this object relate to the crime?\",\n",
    "    \"Who do you think is the suspect and why?\"\n",
    "]\n",
    "\n",
    "# Loop through each step in the chain of thought and get responses\n",
    "for step in prompts:\n",
    "    response = llm_chain.run(thought_step=step)\n",
    "    print(f\"Prompt: {step}\")\n",
    "    print(f\"Response: {response.strip()}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8253ff2d-25f5-4289-a4f1-1f1d2b346381",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 [3.10]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
