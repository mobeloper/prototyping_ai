{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7WOjV7vo9cT6",
   "metadata": {
    "id": "7WOjV7vo9cT6"
   },
   "source": [
    "# __Demo: Self-Consistency Prompting with LangChain and OpenAI__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZKzMpVFbOoWU",
   "metadata": {
    "id": "ZKzMpVFbOoWU"
   },
   "source": [
    "## __Steps to Perform:__\n",
    "\n",
    "Step 1: Set up the OpenAI API Key\n",
    "\n",
    "Step 2: Define the Self-Consistency Prompt Template\n",
    "\n",
    "Step 3: Create the Chain and Run the Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AfdqBdeKPnVX",
   "metadata": {
    "id": "AfdqBdeKPnVX"
   },
   "source": [
    "### __Step 1: Set up the OpenAI API Key__\n",
    "- Import the required libraries and set up the OpenAI API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9a0ea85-80ba-4af5-bc64-73d74a28b57f",
   "metadata": {
    "id": "c9a0ea85-80ba-4af5-bc64-73d74a28b57f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/voc/work/.local/lib/python3.10/site-packages/langchain/llms/openai.py:241: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/voc/work/.local/lib/python3.10/site-packages/langchain/llms/openai.py:898: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Set up the OpenAI API Key\n",
    "#os.environ[\"OPENAI_API_KEY\"] = \"your_openai_api_key\"\n",
    "\n",
    "# Initialize the OpenAI model with temperature > 0 for varied outputs\n",
    "llm = OpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IPE1LxgOPSUo",
   "metadata": {
    "id": "IPE1LxgOPSUo"
   },
   "source": [
    "### __Step 2: Define the Self-Consistency Prompt Template__\n",
    "We use a prompt template to ask the model to generate multiple lines of reasoning for the given problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d0d44b2-14fd-45f0-b2cc-9ca440887758",
   "metadata": {
    "id": "7d0d44b2-14fd-45f0-b2cc-9ca440887758"
   },
   "outputs": [],
   "source": [
    "# Define a self-consistency prompt template\n",
    "template = \"\"\"\n",
    "Question: {question}\n",
    "\n",
    "Generate three different lines of reasoning to solve the question. Each line should approach the problem differently.\n",
    "\n",
    "Line of Reasoning 1:\n",
    "Line of Reasoning 2:\n",
    "Line of Reasoning 3:\n",
    "\n",
    "Based on these lines of reasoning, the most consistent answer is:\n",
    "\"\"\"\n",
    "\n",
    "# Create the LangChain prompt template\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Qo0MsRX5PFqN",
   "metadata": {
    "id": "Qo0MsRX5PFqN"
   },
   "source": [
    "### __Step 3: Create the Chain and Run the Prompt__\n",
    "We use LLMChain to execute the prompt and get responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47154330-0504-4524-b08e-832c479646b6",
   "metadata": {
    "id": "47154330-0504-4524-b08e-832c479646b6",
    "outputId": "52dd08c9-bc0c-4ced-cc2b-619e3a08fa68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Response:\n",
      " Line of Reasoning 1: The weight of an object is determined by its mass, not the number of individual items. Since feathers are much lighter than a weight of 30 pounds, the 30-pound weight is heavier than 1000 feathers.\n",
      "\n",
      "Line of Reasoning 2: Feathers are generally very light, so even though there are 1000 of them, they would still weigh less than a 30-pound weight. Therefore, the 30-pound weight is heavier than 1000 feathers.\n",
      "\n",
      "Line of Reasoning 3: To compare the weight of 1000 feathers to a 30-pound weight, we need to convert the weight of feathers into pounds. Since a feather weighs significantly less than a pound, the collective weight of 1000 feathers would still be less than 30 pounds. Therefore, the 30-pound weight is heavier than 1000 feathers.\n",
      "\n",
      "Based on these lines of reasoning, the most consistent answer is that a 30-pound weight is heavier than 1000 feathers.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the LangChain LLMChain\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "# Define the question\n",
    "question = \"Which is heavier: 1000 feathers or a 30-pound weight?\"\n",
    "\n",
    "# Run the chain\n",
    "response = llm_chain.run(question)\n",
    "print(\"Final Response:\\n\", response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_5hsOXzWPufh",
   "metadata": {
    "id": "_5hsOXzWPufh"
   },
   "source": [
    "You have learned how to use LangChain and OpenAI to generate creative content from prompts. You have also gained experience using self-consistency prompting to guide the modelâ€™s output."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 [3.10]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
