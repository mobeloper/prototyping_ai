{"cells":[{"cell_type":"markdown","source":["# **Demo: Langchain Model Prompt Outputparser**"],"metadata":{"id":"g_gBxYH8kIqp"},"id":"g_gBxYH8kIqp"},{"cell_type":"markdown","source":["# **Steps to Perform:**\n","\n","1. Set up the Environment\n","2. Call Direct API to OpenAI\n","3. Call the Direct API at OpenAI\n","4. Use the Chat Model\n","5. Format a New Message\n","6. Generate a Response in a New Style\n","7. Output Parsers\n","8. Use the Output Parser"],"metadata":{"id":"sx4ZUW69kPdR"},"id":"sx4ZUW69kPdR"},{"cell_type":"markdown","source":["# **Step 1: Set up the Environment**\n","\n","\n","\n","*   Install the required packages and configure the environment, including OpenAI and LangChain, for making API calls.\n","*   Import essential modules and set up the OpenAI API key for making direct API calls to OpenAI through langchain.\n","\n","\n"],"metadata":{"id":"SW2hyf3cE_4g"},"id":"SW2hyf3cE_4g"},{"cell_type":"code","execution_count":null,"id":"25e19e5c-ae2c-4d86-984d-488bae1e04c0","metadata":{"id":"25e19e5c-ae2c-4d86-984d-488bae1e04c0"},"outputs":[],"source":["import os\nfrom openai import OpenAI\n\nclient = OpenAI()\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.prompts import ChatPromptTemplate"]},{"cell_type":"markdown","source":["# **Step 2: Call the Direct API at OpenAI**\n","\n","\n","\n","*   Create a function called **get_completion** that receives a prompt and model as input and provides a completion as output.\n","*   Verify the functionality of the function by asking a straightforward question, such as **What is 1+1?**."],"metadata":{"id":"wJ7Vf0liFig7"},"id":"wJ7Vf0liFig7"},{"cell_type":"code","execution_count":null,"id":"e120e00f-5f45-43a9-8b5a-93b20ff6b797","metadata":{"id":"e120e00f-5f45-43a9-8b5a-93b20ff6b797"},"outputs":[],"source":["def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n    messages = [{\"role\": \"user\", \"content\": prompt}]\n    response = client.chat.completions.create(model=model,\n    messages=messages,\n    temperature=0)\n    return response.choices[0].message.content"]},{"cell_type":"code","execution_count":null,"id":"8be4dbce-5ecd-44e3-a54f-582790efc014","metadata":{"id":"8be4dbce-5ecd-44e3-a54f-582790efc014","outputId":"41ab5b15-619f-42e0-a559-f350ddefcf33"},"outputs":[{"name":"stdout","output_type":"stream","text":["1+1 equals 2.\n"]}],"source":["print(get_completion(\"What is 1+1?\"))"]},{"cell_type":"markdown","source":["# **Step 3: Call API Through LangChain**\n","\n","\n","\n","*   Use LangChain by creating an instance of the ChatOpenAI class.\n","*   Modify parameters like **customer_style** and **customer_email** to influence the tone and formality of the generated responses.\n","\n","\n"],"metadata":{"id":"Oe-lkvcsHBpZ"},"id":"Oe-lkvcsHBpZ"},{"cell_type":"code","execution_count":null,"id":"c34a80a1-14e6-4eb0-a0f4-4753f215e571","metadata":{"id":"c34a80a1-14e6-4eb0-a0f4-4753f215e571"},"outputs":[],"source":["# Start by creating an instance of the ChatOpenAI class.\nchat = ChatOpenAI(temperature=0.0)\n\n# Define a template for our prompts.\ntemplate_string = \"\"\"Translate the text that is delimited by triple backticks into a style that is {style}. text: ```{text}```\"\"\"\nprompt_template = ChatPromptTemplate.from_template(template_string)\n\n# Use this template to format our messages.\ncustomer_style = \"American English in a casual tone\"\ncustomer_email = \"\"\"\nI'm super excited about the new gaming console I bought! It arrived in just 2 days and I've been playing non-stop. Totally worth the price!\n\"\"\"\n\ncustomer_messages = prompt_template.format_messages(\n                    style=customer_style,\n                    text=customer_email)"]},{"cell_type":"markdown","source":["# **Step 4: Use the Chat Model**\n","\n","\n","\n","\n","*   Use the ChatOpenAI instance to produce a response in the designated style, aligning with the formatted messages.\n","\n","\n"],"metadata":{"id":"juFhjkD3HNC5"},"id":"juFhjkD3HNC5"},{"cell_type":"code","execution_count":null,"id":"dfc06b78-7329-4eec-a7ae-b4d5289edce0","metadata":{"id":"dfc06b78-7329-4eec-a7ae-b4d5289edce0","outputId":"b5fc5870-669a-4c4e-d68c-319d8c3c107c"},"outputs":[{"name":"stdout","output_type":"stream","text":["I'm really pumped about the new gaming console I bought! It arrived in only 2 days and I've been playing non-stop. Totally worth the money!\n"]}],"source":["# Use our ChatOpenAI instance to generate a response.\ncustomer_response = chat(customer_messages)\nprint(customer_response.content)"]},{"cell_type":"markdown","source":["# **Step 5: Format a New Message**\n","\n","\n","*   Format the newly created message in the designated style, preparing it for interaction with the chat model.\n","\n","\n"],"metadata":{"id":"F5MQfocOIYUz"},"id":"F5MQfocOIYUz"},{"cell_type":"code","execution_count":null,"id":"7a23d343-ea4a-49ba-96df-964508d220f5","metadata":{"id":"7a23d343-ea4a-49ba-96df-964508d220f5","outputId":"6f8aecf1-719e-4c5e-ad84-6e467e2fe796"},"outputs":[{"name":"stdout","output_type":"stream","text":["Translate the text that is delimited by triple backticks into a style that is a cheerful tone that speaks in English Pirate. text: ```Hey there, we're glad you're enjoying your new gaming console. Game on!```\n"]}],"source":["# Format a new message using a different style.\nservice_reply = \"Hey there, we're glad you're enjoying your new gaming console. Game on!\"\nservice_style_pirate = \"a cheerful tone that speaks in English Pirate\"\nservice_messages = prompt_template.format_messages(style=service_style_pirate, text=service_reply)\nprint(service_messages[0].content)"]},{"cell_type":"markdown","source":["# **Step 6: Generate a Response in a New Style**\n","\n","\n","*   Retrieve the generated response, in this case, would be in the manner of a polite English Pirate.\n","\n","\n"],"metadata":{"id":"pUsg6O24IlNV"},"id":"pUsg6O24IlNV"},{"cell_type":"code","execution_count":null,"id":"af52bbad-116f-4ad9-9471-f11389be379e","metadata":{"id":"af52bbad-116f-4ad9-9471-f11389be379e","outputId":"e3be2ec5-fb33-48ed-a270-904d53632af6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Arrr, me hearties! Avast ye! We be mighty pleased to see ye enjoyin' yer shiny new gaming console. Set sail on yer gaming adventures, me matey! Yo ho ho!\n"]}],"source":["# Generate a response in our new style using the ChatOpenAI instance.\nservice_response = chat(service_messages)\nprint(service_response.content)"]},{"cell_type":"markdown","source":["# **Step 7: Output Parsers**\n","\n","\n","*   Clearly outline the preferred format for the language model's output using an output parser.\n","\n","\n","\n","\n"],"metadata":{"id":"LMgWoftUI2E4"},"id":"LMgWoftUI2E4"},{"cell_type":"code","execution_count":null,"id":"4ab54bea-72ae-4db1-bc0d-25ca66a6c052","metadata":{"id":"4ab54bea-72ae-4db1-bc0d-25ca66a6c052"},"outputs":[],"source":["# Define how we would like the output from the language model to look like.\ndesired_output = {\n    \"gift\": False,\n    \"delivery_days\": 2,\n    \"price_value\": \"Totally worth the price!\"\n}\n\n# Create a customer review and a template for extracting information from the review.\ncustomer_review = \"\"\"\\\nI'm super excited about the new gaming console I bought! It arrived in just 2 days and I've been playing non-stop. Totally worth the price!\n\"\"\"\n\nreview_template = \"\"\"\\\nFor the following text, extract the following information:\ngift: Was the item purchased as a gift for someone else? \\\nAnswer True if yes, False if not or unknown.\ndelivery_days: How many days did it take for the product \\\nto arrive? If this information is not found, output -1.\nprice_value: Extract any sentences about the value or price,\\\nand output them as a comma separated Python list.\nFormat the output as JSON with the following keys:\ngift\ndelivery_days\nprice_value\ntext: {text}\n\"\"\""]},{"cell_type":"markdown","source":["# **Step 8: Use the Output Parser**\n","\n","\n","*   Use the defined schemas to instantiate the **StructuredOutputParser** class, forming an instance named **output_parser**.\n","\n","\n","\n","\n"],"metadata":{"id":"irshmpi-JDBI"},"id":"irshmpi-JDBI"},{"cell_type":"code","execution_count":null,"id":"704af701-ab09-40ff-88f9-46c8797e27a0","metadata":{"id":"704af701-ab09-40ff-88f9-46c8797e27a0"},"outputs":[],"source":["from langchain.output_parsers import ResponseSchema, StructuredOutputParser\ngift_schema = ResponseSchema(name=\"gift\",\ndescription=\"Was the product given as a present to someone? \\\nAnswer True if yes, False if not or unknown.\")\ndelivery_days_schema = ResponseSchema(name=\"delivery_days\",\ndescription=\"How many days was the delivery period for the product? \\\nIf this information is not found, output -1.\")\nprice_value_schema = ResponseSchema(name=\"price_value\",\ndescription=\"Extract any sentences about the cost or value of the product, \\\nand output them as a comma separated Python list.\")\nresponse_schemas = [gift_schema, delivery_days_schema, price_value_schema]"]},{"cell_type":"markdown","source":["You can use these format instructions to create a new prompt, generate a response, and parse the output."],"metadata":{"id":"87qXvbN2JZcJ"},"id":"87qXvbN2JZcJ"},{"cell_type":"code","execution_count":null,"id":"b4e2b570-4c61-41ad-aa5d-fc9e18f27a06","metadata":{"id":"b4e2b570-4c61-41ad-aa5d-fc9e18f27a06"},"outputs":[],"source":["output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"]},{"cell_type":"code","execution_count":null,"id":"e68b0f1b-06cb-4ddb-b8d3-0edb2a5d611d","metadata":{"id":"e68b0f1b-06cb-4ddb-b8d3-0edb2a5d611d"},"outputs":[],"source":["format_instructions = output_parser.get_format_instructions()"]},{"cell_type":"code","execution_count":null,"id":"47a4af5d-bb0a-4f92-b4d6-0039d21977f6","metadata":{"id":"47a4af5d-bb0a-4f92-b4d6-0039d21977f6","outputId":"6a49cf17-f17f-4670-e773-349f8b5e1aef"},"outputs":[{"name":"stdout","output_type":"stream","text":["The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n","\n","```json\n","{\n","\t\"gift\": string  // Was the product given as a present to someone? Answer True if yes, False if not or unknown.\n","\t\"delivery_days\": string  // How many days was the delivery period for the product? If this information is not found, output -1.\n","\t\"price_value\": string  // Extract any sentences about the cost or value of the product, and output them as a comma separated Python list.\n","}\n","```\n"]}],"source":["print(format_instructions)"]},{"cell_type":"code","source":["prompt = ChatPromptTemplate.from_template(template=review_template)\nmessages = prompt.format_messages(text=customer_review, format_instructions=format_instructions)\n\nresponse = chat(messages)\noutput_dict = output_parser.parse(response.content)"],"metadata":{"id":"-Xjtw5S-60kt"},"id":"-Xjtw5S-60kt","execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(output_dict)"],"metadata":{"id":"cz3X108I605R"},"id":"cz3X108I605R","execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(output_dict.get('text'))"],"metadata":{"id":"cS17iq6m7EJY"},"id":"cS17iq6m7EJY","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Conclusion:**\n","In this activity, you successfully configured the environment, utilized OpenAI's Direct API, interacted with the Chat Model, formatted messages, generated responses, and employed output parsers. The process was efficient and demonstrated effective communication with the OpenAI models."],"metadata":{"id":"3T4_T6V0JoPJ"},"id":"3T4_T6V0JoPJ"},{"cell_type":"code","source":[""],"metadata":{"id":"nwAXmuQGKqbb"},"id":"nwAXmuQGKqbb","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.2"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}