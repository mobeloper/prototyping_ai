{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "Rbl8J3xS0SuN",
   "metadata": {
    "id": "Rbl8J3xS0SuN"
   },
   "source": [
    "# **Demo: Text Summarizer**\n",
    "\n",
    "This demo guides you through the process of creating an Arxiv paper summarizer that automates downloading a research paper as a PDF, extracting its content, and generating a concise summary. For this demonstration, the example paper titled \"The Impact of Generative Artificial Intelligence\" will be used. The summarizer processes the document, extracts key insights, and delivers a structured summary using LangChain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "M7tVy2Jh0pdJ",
   "metadata": {
    "id": "M7tVy2Jh0pdJ"
   },
   "source": [
    "##**Steps to Perform:**\n",
    "\n",
    "*   Step 1: Import the Necessary Libraries\n",
    "*   Step 2: Download and Read the PDF\n",
    "*   Step 3: Extract Text from the PDF\n",
    "*   Step 4: Count the Tokens in the Extracted Text\n",
    "*   Step 5: Use LangChain to Generate a Summary of the Paper\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jQZbPihb1dMF",
   "metadata": {
    "id": "jQZbPihb1dMF"
   },
   "source": [
    "###**Step 1: Import the Necessary Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03fbcc3-46d9-4fd6-978f-827900e89044",
   "metadata": {
    "id": "a03fbcc3-46d9-4fd6-978f-827900e89044",
    "outputId": "a708d2b9-7e74-41dd-b1ee-3e48b6e1c895"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages: 9\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from PyPDF2 import PdfReader\n",
    "import tiktoken\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    PromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.callbacks import get_openai_callback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WSJ764yL1cNR",
   "metadata": {
    "id": "WSJ764yL1cNR"
   },
   "source": [
    "###**Step 2: Download and Read the PDF**\n",
    "\n",
    "*   Define the path of the paper.\n",
    "*   Read the PDF using **PdfReader**.\n",
    "*   Print the number of pages.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fyHkw-O81aq2",
   "metadata": {
    "id": "fyHkw-O81aq2"
   },
   "outputs": [],
   "source": [
    "# Define the path of the paper\n",
    "PAPER_PATH = \"arxiv_impact_of_GENAI.pdf\"\n",
    "\n",
    "# Read the PDF\n",
    "reader = PdfReader(PAPER_PATH)\n",
    "\n",
    "# Print the number of pages in the PDF\n",
    "print(f\"Number of pages: {len(reader.pages)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ysMvCkBa1vvr",
   "metadata": {
    "id": "ysMvCkBa1vvr"
   },
   "source": [
    "###**Step 3: Extract Text from the PDF**\n",
    "\n",
    "*   Initialize an empty list to store text parts.\n",
    "*   Define a function to visit the body of the text.\n",
    "*   Extract the text from each page of the PDF.\n",
    "*   Join the parts of the text into a single string.\n",
    "*   Print the extracted text.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c6951f-cc6c-4049-96e5-28be876c9d91",
   "metadata": {
    "id": "a6c6951f-cc6c-4049-96e5-28be876c9d91"
   },
   "outputs": [],
   "source": [
    "# Initialize an empty list to store the parts of the text\n",
    "parts = []\n",
    "\n",
    "# Define a function to visit the body of the text\n",
    "def visitor_body(text, cm, tm, fontDict, fontSize):\n",
    "    y = tm[5]\n",
    "    if y > 50 and y < 720:\n",
    "        parts.append(text)\n",
    "\n",
    "# Extract the text from each page of the PDF\n",
    "for page in reader.pages:\n",
    "    page.extract_text(visitor_text=visitor_body)\n",
    "\n",
    "# Join the parts of the text into a single string\n",
    "text_body = \"\".join(parts)\n",
    "\n",
    "# Print the extracted text\n",
    "print(text_body)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rdHgoLYP2Wnp",
   "metadata": {
    "id": "rdHgoLYP2Wnp"
   },
   "source": [
    "###**Step 4: Count the Tokens in the Extracted Text**\n",
    "\n",
    "*   Define a function to count the tokens in a text string.\n",
    "*   Count the tokens in the extracted text.\n",
    "*   Print the number of tokens.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5260eab-5ba8-4c36-868b-56133230f6ea",
   "metadata": {
    "id": "f5260eab-5ba8-4c36-868b-56133230f6ea"
   },
   "outputs": [],
   "source": [
    "# Define a function to count the tokens in a text string\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "# Count the tokens in the extracted text\n",
    "num_tokens = num_tokens_from_string(text_body, \"gpt-3.5-turbo\")\n",
    "\n",
    "# Print the number of tokens\n",
    "print(num_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YMAmFNbo24ga",
   "metadata": {
    "id": "YMAmFNbo24ga"
   },
   "source": [
    "###**Step 5: Use LangChain to Generate a Summary of the Paper**\n",
    "\n",
    "*   Define the system and human prompts.\n",
    "*   Create the **ChatPromptTemplate** object.\n",
    "*   Create the **ChatOpenAI** object.\n",
    "*   Create the **LLMChain** object.\n",
    "*   Run the **LLMChain**.\n",
    "*   Print the output.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8359a8a2-3495-4007-af6c-6f6dbe3f9df2",
   "metadata": {
    "id": "8359a8a2-3495-4007-af6c-6f6dbe3f9df2"
   },
   "outputs": [],
   "source": [
    "# Define the system prompt\n",
    "context_template = \"You are a helpful AI Researcher that specializes in analyzing ML, AI, and LLM papers. Please use all your expertise to approach this task. Output your content in markdown format and include titles where relevant.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(context_template)\n",
    "\n",
    "# Define the human prompt\n",
    "human_template = \"Please summarize this paper focusing on the key important takeaways for each section. Expand the summary on methods so they can be clearly understood. \\n\\n PAPER: \\n\\n{paper_content}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate(\n",
    "        prompt=PromptTemplate(\n",
    "            template=human_template,\n",
    "            input_variables=[\"paper_content\"],\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Create the ChatPromptTemplate object\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "# Create the ChatOpenAI object\n",
    "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo-16k\", temperature=0.2)\n",
    "\n",
    "# Create the LLMChain object\n",
    "summary_chain = LLMChain(llm=chat, prompt=chat_prompt_template)\n",
    "\n",
    "# Run the LLMChain and print the output\n",
    "with get_openai_callback() as cb:\n",
    "    output = summary_chain.run(text_body)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39HdSjiN3ZKD",
   "metadata": {
    "id": "39HdSjiN3ZKD"
   },
   "source": [
    "###**Conclusion**\n",
    "\n",
    "This demo provides a step-by-step guide on how to build an Arxiv paper summarizer using Python. By following these steps.\n",
    "\n",
    "**Note:**\n",
    "*   Save the output as a text file.\n",
    "*   Name the text file **Summary.txt**.\n",
    "*   This file will be used in the next session for benchmarking purposes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eu7JlPVaAFpF",
   "metadata": {
    "id": "eu7JlPVaAFpF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 [3.10]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
