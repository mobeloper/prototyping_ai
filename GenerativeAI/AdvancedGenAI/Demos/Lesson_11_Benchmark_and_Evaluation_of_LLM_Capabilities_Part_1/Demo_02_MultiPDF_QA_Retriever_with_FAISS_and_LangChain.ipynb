{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IPNfNQMHsTzw"
   },
   "source": [
    "# **Demo: MultiPDF QA Retriever with FAISS and LangChain**\n",
    "\n",
    "In this demo, you will learn how to use LangChain to create a MultiPDF retriever with FAISS. This demo is performed on new generative AI research paper PDFs. You will understand how to load and process documents, create a database, make a retriever, create a chain, and use the retriever to ask questions and get answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UHNcYIClspLl"
   },
   "source": [
    "## **Steps to Perform:**\n",
    "\n",
    "*   Step 1: Importing the Necessary Libraries\n",
    "*   Step 2: Loading and Splitting\n",
    "*   Step 3: Loading the OpenAI Embeddings\n",
    "*   Step 4: Creating and Loading the Database\n",
    "*   Step 5: Creating and Using the Retriever\n",
    "*   Step 6: Passing the Query\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uiVumMWatiZP"
   },
   "source": [
    "### **Step 1: Importing the Necessary Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-rlv9F3SsZBz"
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader, PyPDFLoader, DirectoryLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "import os\n",
    "import openai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mAT815IEtnw0"
   },
   "source": [
    "### **Step 2: Loading and Splitting**\n",
    "\n",
    "\n",
    "*   Create a directory named `GenAI_Papers`.\n",
    "*   Load the PDF documents in the directory.\n",
    "*   Split the documents into smaller chunks using the **RecursiveCharacterTextSplitter**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "DGoEWZK1tqYI"
   },
   "outputs": [],
   "source": [
    "# Loading the documents\n",
    "doc_loader = DirectoryLoader('GenAI_Papers', glob=\"./*.pdf\", loader_cls=PyPDFLoader)\n",
    "documents = doc_loader.load()\n",
    "\n",
    "# Splitting the documents\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(documents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RLZTwm7DuKe4"
   },
   "source": [
    "### **Step 3: Loading the OpenAI Embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "F-iBYG45uDIh"
   },
   "outputs": [],
   "source": [
    "openai_embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KqaG3jbAuS0K"
   },
   "source": [
    "### **Step 4: Creating and Loading the Database**\n",
    "\n",
    "*   Create a database to store the embedded text.\n",
    "*   Load the database to bring it back into memory from the disk.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "rDcTkjWOv11M"
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# Create embeddings for texts\n",
    "text_embeddings = openai_embeddings.embed_documents([text.page_content for text in texts])\n",
    "\n",
    "# Creating the FAISS database\n",
    "faiss_index = FAISS.from_texts([text.page_content for text in texts], openai_embeddings)\n",
    "\n",
    "# Save the FAISS index\n",
    "faiss_index.save_local('faiss_index')\n",
    "\n",
    "# Loading the FAISS index\n",
    "faiss_index = FAISS.load_local('faiss_index', openai_embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nh2K3SO4wBkN"
   },
   "source": [
    "### **Step 5: Creating and Using the Retriever**\n",
    "\n",
    "*   Create a retriever using the vector database.\n",
    "*   Use the retriever to get relevant documents for a specific query.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "hOBLjcr5wX6X"
   },
   "outputs": [],
   "source": [
    "# Creating retriever\n",
    "retriever = faiss_index.as_retriever()\n",
    "\n",
    "# Using retriever\n",
    "docs = retriever.get_relevant_documents(\"What is toolformer?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJDyfzRwwhEU"
   },
   "source": [
    "### **Step 6: Passing the Query**\n",
    "\n",
    "*   Pass the query to the vector database.\n",
    "*   Print the content of the most relevant document.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Vc3fqL4ZwmBX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with size, measured by the number of trainable parameters: f or example, Wei et al. (2022b ) demonstrate\n",
      "that LLMs become able to perform some BIG-bench tasks3via few-shot prompting once a certain scale is\n",
      "attained. Although a recent line of work yielded smaller LMs that retain some capabilities from their largest\n",
      "counterpart ( Hoﬀmann et al. ,2022), the size and need for data of LLMs can be impractical for tra ining\n",
      "but also maintenance: continual learning for large models r emains an open research question ( Scialom et al. ,\n",
      "2022). Other limitations of LLMs are discussed by Goldberg (2023) in the context of ChatGPT , a chatbot\n",
      "built upon GPT3 .\n",
      "We argue these issues stem from a fundamental defect of LLMs: they are generally trained to perform\n",
      "statistical language modeling given (i) a single parametri c model and (ii) a limited context, typically the n\n",
      "previous or surrounding tokens. While nhas been growing in recent years thanks to software and hardw are\n"
     ]
    }
   ],
   "source": [
    "query = \"A fundamental limitation of HMMs\"\n",
    "docs = faiss_index.similarity_search(query)\n",
    "print(docs[0].page_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uT00SGQrw3Dw"
   },
   "source": [
    "### **Conclusion**\n",
    "\n",
    "By the end of this demo, you have a clear understanding of how to use LangChain’s MultiPDF retriever with FAISS. You’ve learned how to load and process documents, create a database, make a retriever, and use the retriever to ask questions. This knowledge will help you effectively utilize LangChain’s capabilities in your projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 [3.10]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
