{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TScI13I9eeXj"
      },
      "source": [
        "# Global Vectors for Word Representation\n",
        "\n",
        "In Natural Language Processing (NLP), a glove (Global Vectors for Word Representation) is a type of word embedding that represents words as vectors in a high-dimensional space. The goal of word embeddings is to capture the semantic meaning and context of words, allowing machines to understand the nuances of human language.\n",
        "\n",
        "GloVe is a specific type of word embedding that was introduced in a 2014 paper by Pennington, Socher, and Manning. It's based on the idea that words that appear in similar contexts tend to have similar meanings. The GloVe algorithm uses a combination of co-occurrence statistics and matrix factorization to learn dense vector representations of words.\n",
        "\n",
        "Here's a high-level overview of how GloVe works:\n",
        "\n",
        "1. **Co-occurrence matrix**: Create a matrix where each row represents a word, and each column represents a context (e.g., a sentence or a document). The cell at row i and column j contains the frequency of word i appearing in the context of word j.\n",
        "2. **Matrix factorization**: Factorize the co-occurrence matrix into two lower-dimensional matrices, U and V, such that the product UV approximates the original matrix. This is done using a technique called stochastic gradient descent.\n",
        "3. **Vector representation**: Each row of the U matrix represents a word, and each column of the V matrix represents a context. The dot product of the row vector for word i and the column vector for context j gives the predicted probability of word i appearing in context j.\n",
        "\n",
        "The resulting vector representations of words are dense, real-valued vectors that capture the semantic meaning and context of each word. These vectors can be used for a variety of NLP tasks, such as:\n",
        "\n",
        "* Text classification\n",
        "* Sentiment analysis\n",
        "* Information retrieval\n",
        "* Language modeling\n",
        "* Machine translation\n",
        "\n",
        "GloVe has several advantages over other word embedding techniques, including:\n",
        "\n",
        "* **Scalability**: GloVe can handle large vocabularies and large datasets.\n",
        "* **Flexibility**: GloVe can be used for a wide range of NLP tasks.\n",
        "* **Interpretability**: The vector representations of words can be visualized and interpreted.\n",
        "\n",
        "However, GloVe also has some limitations, such as:\n",
        "\n",
        "* **Computational complexity**: The matrix factorization step can be computationally expensive.\n",
        "* **Hyperparameter tuning**: The performance of GloVe depends on the choice of hyperparameters, such as the dimensionality of the vector space and the learning rate.\n",
        "\n",
        "Overall, GloVe is a powerful tool for representing words in a high-dimensional space, and it has been widely used in many NLP applications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clPW93w8Wlki",
        "outputId": "55253bd8-498b-4e7a-b3f9-ba4ac5af972e"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '../data/glove.6B.100d.txt'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load the pre-trained GloVe model\u001b[39;00m\n\u001b[1;32m      4\u001b[0m glove_model \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../data/glove.6B.100d.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f:\n\u001b[1;32m      7\u001b[0m         values \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39msplit()\n",
            "File \u001b[0;32m~/.local/lib/python3.11/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/glove.6B.100d.txt'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "#Resources:\n",
        "# https://www.kaggle.com/datasets/sawarn69/glove6b100dtxt\n",
        "#\n",
        "\n",
        "\n",
        "# Load the pre-trained GloVe model\n",
        "glove_model = {}\n",
        "\n",
        "# with open('/content/glove.6B.100d.txt', 'r') as f:\n",
        "with open('../data/glove.6B.100d.txt', 'r') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = np.asarray(values[1:], dtype='float32')\n",
        "        glove_model[word] = vector\n",
        "\n",
        "# Define two words to compare\n",
        "word1 = 'hello'\n",
        "word2 = 'world'\n",
        "\n",
        "# Get the vector representations of the words\n",
        "vector1 = glove_model.get(word1)\n",
        "vector2 = glove_model.get(word2)\n",
        "\n",
        "\n",
        "print(f'word embedding from {word1}:{vector1}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Calculate the cosine similarity between the two words\n",
        "similarity = np.dot(vector1, vector2) / (np.linalg.norm(vector1) * np.linalg.norm(vector2))\n",
        "print(f\"Similarity between '{word1}' and '{word2}': {similarity:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HL9KyZdYjJxP"
      },
      "source": [
        "## Train a Classifier with Feature Vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "CgtIH7wLjKKx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from datasets import load_dataset\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "\n",
        "# Step 1: Load GloVe embeddings\n",
        "def load_glove_embeddings(glove_file, word2vec_file):\n",
        "    # Convert GloVe to Word2Vec format if not already done\n",
        "    glove2word2vec(glove_file, word2vec_file)\n",
        "    return KeyedVectors.load_word2vec_format(word2vec_file, binary=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBhMJBB5kzlV"
      },
      "source": [
        "## Load pre-trained embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kmqUzzvk0Fm",
        "outputId": "21f6ba41-9877-41b7-bfa5-06e18c754c95"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-26-3b41b6742975>:14: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
            "  glove2word2vec(glove_file, word2vec_file)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# GloVe files (use smaller dimensions for faster processing)\n",
        "glove_file = \"/content/glove.6B.100d.txt\"\n",
        "word2vec_file = \"/content/glove.6B.100d.word2vec.txt\"\n",
        "\n",
        "glove_model = load_glove_embeddings(glove_file, word2vec_file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgpLF8qgk539"
      },
      "source": [
        "\n",
        "## Step 2: Prepare dataset (using a Hugging Face dataset for demonstration)\n",
        " We'll use the AG News dataset as an example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "OUpyUeImk6O3"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"ag_news\")\n",
        "train_data = dataset[\"train\"]\n",
        "test_data = dataset[\"test\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ha4qqaWblAAp"
      },
      "source": [
        "## Step 3: Text preprocessing and feature extraction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "iTqdLCBZlAUL"
      },
      "outputs": [],
      "source": [
        "\n",
        "def text_to_glove_vector(text, glove_model, embedding_dim=100):\n",
        "    \"\"\"\n",
        "    Converts a text document to a feature vector by averaging its word embeddings.\n",
        "    \"\"\"\n",
        "    words = text.split()\n",
        "    word_vectors = [glove_model[word] for word in words if word in glove_model]\n",
        "    if len(word_vectors) == 0:\n",
        "        return np.zeros(embedding_dim)\n",
        "    return np.mean(word_vectors, axis=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61ulvXpRlEFl"
      },
      "source": [
        "## Create feature matrices for train and test sets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "7eb5IKaqlEl1"
      },
      "outputs": [],
      "source": [
        "X_train = np.array([text_to_glove_vector(text, glove_model) for text in train_data[\"text\"]])\n",
        "X_test = np.array([text_to_glove_vector(text, glove_model) for text in test_data[\"text\"]])\n",
        "\n",
        "# Use integer labels for Naive Bayes\n",
        "y_train = np.array(train_data[\"label\"])\n",
        "y_test = np.array(test_data[\"label\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7p4HplplIbs"
      },
      "source": [
        "\n",
        "## Step 4: Train a Naive Bayes classifier\n",
        "Note: Naive Bayes works best with discrete features; embeddings are continuous.\n",
        "We'll normalize and discretize them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "-VDQTdbmlIue"
      },
      "outputs": [],
      "source": [
        "\n",
        "X_train_discrete = np.round(X_train * 10).astype(int)\n",
        "X_test_discrete = np.round(X_test * 10).astype(int)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuThGqDllQi9"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJS_CEsRkmI7",
        "outputId": "5bf878ee-9ccc-4194-804d-15200a0feef0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.79      0.76      1900\n",
            "           1       0.82      0.85      0.83      1900\n",
            "           2       0.77      0.67      0.72      1900\n",
            "           3       0.71      0.72      0.72      1900\n",
            "\n",
            "    accuracy                           0.76      7600\n",
            "   macro avg       0.76      0.76      0.76      7600\n",
            "weighted avg       0.76      0.76      0.76      7600\n",
            "\n",
            "Accuracy: 0.76\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Train Naive Bayes model\n",
        "nb_classifier = MultinomialNB()\n",
        "shift = np.abs(X_train_discrete.min())  # Find the minimum value\n",
        "X_train_discrete += shift  # Shift all values to be non-negative\n",
        "X_test_discrete += shift\n",
        "\n",
        "nb_classifier.fit(X_train_discrete, y_train)\n",
        "\n",
        "# Step 5: Evaluate the classifier\n",
        "y_pred = nb_classifier.predict(X_test_discrete)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsAC0k03edXA"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
