{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPWIGkSlnwcQ"
      },
      "source": [
        "# N-gram Models\n",
        "\n",
        "N-gram models are a type of statistical model used in natural language processing (NLP) to analyze and generate text. The term \"n-gram\" refers to a sequence of n items, where n is a positive integer.\n",
        "\n",
        "In the context of NLP, an n-gram model is a statistical model that analyzes a sequence of n words or characters in a text and predicts the probability of the next word or character in the sequence. The model is trained on a large corpus of text data and uses the frequencies of the n-grams to make predictions.\n",
        "\n",
        "There are several types of n-gram models, including:\n",
        "\n",
        "1. Unigram models: These models analyze the frequency of individual words or characters in the text.\n",
        "2. Bigram models: These models analyze the frequency of pairs of words or characters in the text.\n",
        "3. Trigram models: These models analyze the frequency of triples of words or characters in the text.\n",
        "4. N-gram models: These models analyze the frequency of sequences of n words or characters in the text.\n",
        "\n",
        "N-gram models are widely used in NLP applications such as:\n",
        "\n",
        "1. Language modeling: N-gram models are used to predict the next word in a sentence or the next character in a sequence.\n",
        "2. Text classification: N-gram models are used to classify text into different categories such as spam vs. non-spam emails.\n",
        "3. Sentiment analysis: N-gram models are used to analyze the sentiment of text, such as determining whether a piece of text is positive, negative, or neutral.\n",
        "4. Machine translation: N-gram models are used to translate text from one language to another.\n",
        "\n",
        "The advantages of n-gram models include:\n",
        "\n",
        "1. Simple to implement: N-gram models are relatively simple to implement and require minimal computational resources.\n",
        "2. Effective for short-range dependencies: N-gram models are effective for modeling short-range dependencies in text, such as the frequency of individual words or pairs of words.\n",
        "3. Can be used for a variety of tasks: N-gram models can be used for a variety of NLP tasks, including language modeling, text classification, sentiment analysis, and machine translation.\n",
        "\n",
        "However, n-gram models also have some limitations, including:\n",
        "\n",
        "1. Limited ability to capture long-range dependencies: N-gram models are limited in their ability to capture long-range dependencies in text, such as the relationships between words that are separated by many words.\n",
        "2. Can be sensitive to the order of words: N-gram models can be sensitive to the order of words in a sentence, which can make them less effective for tasks that require modeling the relationships between words.\n",
        "3. Can be prone to overfitting: N-gram models can be prone to overfitting, which can occur when the model is trained on a small dataset and is unable to generalize well to new data.\n",
        "\n",
        "Overall, n-gram models are a simple and effective way to analyze and generate text, but they have limitations and are not suitable for all NLP tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gwki9PE0nbaV",
        "outputId": "5ce11e5c-bc89-4f7d-f524-1b206506dd1b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     /Users/oysterable/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/oysterable/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import nltk\n",
        "from nltk import word_tokenize, ngrams\n",
        "from collections import defaultdict, Counter\n",
        "import random\n",
        "\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('punkt')\n",
        "\n",
        "class NGramLanguageModel:\n",
        "    def __init__(self, n):\n",
        "        self.n = n\n",
        "        self.model = defaultdict(Counter)\n",
        "\n",
        "    def train(self, text):\n",
        "        tokens = word_tokenize(text.lower())\n",
        "        for ngram in ngrams(tokens, self.n + 1):\n",
        "            self.model[tuple(ngram[:-1])][ngram[-1]] += 1\n",
        "\n",
        "    def generate_next_word(self, context):\n",
        "        if tuple(context) in self.model:\n",
        "            candidates = self.model[tuple(context)].most_common()\n",
        "            total_count = sum(count for word, count in candidates)\n",
        "            r = random.uniform(0, total_count)\n",
        "            for word, count in candidates:\n",
        "                r -= count\n",
        "                if r <= 0:\n",
        "                    return word\n",
        "        return None\n",
        "\n",
        "    def generate_text(self, seed_words, num_words):\n",
        "        context = seed_words[-self.n:]\n",
        "        generated_text = list(seed_words)\n",
        "\n",
        "        for _ in range(num_words):\n",
        "            next_word = self.generate_next_word(context)\n",
        "            if next_word is None:\n",
        "                break\n",
        "            generated_text.append(next_word)\n",
        "            context = generated_text[-self.n:]\n",
        "\n",
        "        return ' '.join(generated_text)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41nIn-1QoCae"
      },
      "source": [
        "## Train trigram model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rBM4CU8roCxa"
      },
      "outputs": [],
      "source": [
        "# Example usage\n",
        "corpus = \"\"\"\n",
        "The quick brown fox jumps over the lazy dog. The dog was not amused.\n",
        "The fox was quite proud of its agility. Quick reflexes are essential for survival in the wild.\n",
        "The lazy dog eventually got up and chased the fox, but it was too late.\n",
        "\"\"\"\n",
        "\n",
        "model = NGramLanguageModel(n=2)\n",
        "model.train(corpus)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHXBFpIioJtr"
      },
      "source": [
        "## Generate text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7MQ8FRsoJ_q",
        "outputId": "759e6d4c-5af7-4d88-f01e-0dce5346c908"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated text:\n",
            "The quick\n",
            "\n",
            "Predicted next word after 'the lazy': dog\n",
            "\n",
            "Some trigrams and their frequency:\n",
            "('the', 'quick'): {'brown': 1}\n",
            "('quick', 'brown'): {'fox': 1}\n",
            "('brown', 'fox'): {'jumps': 1}\n",
            "('fox', 'jumps'): {'over': 1}\n",
            "('jumps', 'over'): {'the': 1}\n"
          ]
        }
      ],
      "source": [
        "seed = [\"The\", \"quick\"]\n",
        "generated_text = model.generate_text(seed, num_words=20)\n",
        "print(\"Generated text:\")\n",
        "print(generated_text)\n",
        "\n",
        "# Next word prediction\n",
        "context = [\"the\", \"lazy\"]\n",
        "next_word = model.generate_next_word(context)\n",
        "print(f\"\\nPredicted next word after '{' '.join(context)}': {next_word}\")\n",
        "\n",
        "# Print some n-grams and their frequency\n",
        "print(\"\\nSome trigrams and their frequency:\")\n",
        "for context, word_freq in list(model.model.items())[:5]:\n",
        "    print(f\"{context}: {dict(word_freq)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZ2sNxFpnu5W"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
