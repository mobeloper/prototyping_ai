{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29uJaYbEoaaV",
        "outputId": "7f898b98-782a-4359-f6a1-4a27cedf571c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text: The quick brown fox jumps over the lazy dog. The dog was not amused.\n",
            "\n",
            "1-grams:\n",
            "  the\n",
            "  quick\n",
            "  brown\n",
            "  fox\n",
            "  jumps\n",
            "  over\n",
            "  the\n",
            "  lazy\n",
            "  dog\n",
            "  .\n",
            "  the\n",
            "  dog\n",
            "  was\n",
            "  not\n",
            "  amused\n",
            "  .\n",
            "\n",
            "Most common 1-grams:\n",
            "  the: 3\n",
            "  dog: 2\n",
            "  .: 2\n",
            "\n",
            "2-grams:\n",
            "  the quick\n",
            "  quick brown\n",
            "  brown fox\n",
            "  fox jumps\n",
            "  jumps over\n",
            "  over the\n",
            "  the lazy\n",
            "  lazy dog\n",
            "  dog .\n",
            "  . the\n",
            "  the dog\n",
            "  dog was\n",
            "  was not\n",
            "  not amused\n",
            "  amused .\n",
            "\n",
            "Most common 2-grams:\n",
            "  the quick: 1\n",
            "  quick brown: 1\n",
            "  brown fox: 1\n",
            "\n",
            "3-grams:\n",
            "  the quick brown\n",
            "  quick brown fox\n",
            "  brown fox jumps\n",
            "  fox jumps over\n",
            "  jumps over the\n",
            "  over the lazy\n",
            "  the lazy dog\n",
            "  lazy dog .\n",
            "  dog . the\n",
            "  . the dog\n",
            "  the dog was\n",
            "  dog was not\n",
            "  was not amused\n",
            "  not amused .\n",
            "\n",
            "Most common 3-grams:\n",
            "  the quick brown: 1\n",
            "  quick brown fox: 1\n",
            "  brown fox jumps: 1\n",
            "\n",
            "Generated text using trigrams:\n",
            "quick brown fox jumps over the lazy dog . the dog was not amused .\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize, ngrams\n",
        "from collections import Counter\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "def generate_ngrams(text, n):\n",
        "    # Tokenize the text\n",
        "    tokens = word_tokenize(text.lower())\n",
        "\n",
        "    # Generate n-grams\n",
        "    n_grams = list(ngrams(tokens, n))\n",
        "\n",
        "    return n_grams\n",
        "\n",
        "def analyze_ngrams(text):\n",
        "    print(f\"Original text: {text}\")\n",
        "\n",
        "    # Generate and analyze unigrams, bigrams, and trigrams\n",
        "    for n in range(1, 4):\n",
        "        n_grams = generate_ngrams(text, n)\n",
        "\n",
        "        print(f\"\\n{n}-grams:\")\n",
        "        for gram in n_grams:\n",
        "            print(f\"  {' '.join(gram)}\")\n",
        "\n",
        "        # Count frequency of each n-gram\n",
        "        gram_freq = Counter(n_grams)\n",
        "\n",
        "        print(f\"\\nMost common {n}-grams:\")\n",
        "        for gram, count in gram_freq.most_common(3):\n",
        "            print(f\"  {' '.join(gram)}: {count}\")\n",
        "\n",
        "# Example usage\n",
        "text = \"The quick brown fox jumps over the lazy dog. The dog was not amused.\"\n",
        "\n",
        "analyze_ngrams(text)\n",
        "\n",
        "# Bonus: Using n-grams for text generation\n",
        "def generate_text(text, n, num_words):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    n_grams = list(ngrams(tokens, n))\n",
        "\n",
        "    # Start with a random n-gram\n",
        "    import random\n",
        "    current = random.choice(n_grams)\n",
        "    result = list(current)\n",
        "\n",
        "    for _ in range(num_words - n):\n",
        "        possible_next = [gram for gram in n_grams if gram[:-1] == current[1:]]\n",
        "        if not possible_next:\n",
        "            break\n",
        "        next_gram = random.choice(possible_next)\n",
        "        result.append(next_gram[-1])\n",
        "        current = next_gram\n",
        "\n",
        "    return ' '.join(result)\n",
        "\n",
        "# Generate text using trigrams\n",
        "generated_text = generate_text(text, 3, 20)\n",
        "print(\"\\nGenerated text using trigrams:\")\n",
        "print(generated_text)\n"
      ]
    }
  ]
}