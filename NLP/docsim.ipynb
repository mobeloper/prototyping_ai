{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqY3_vN_gSN4"
      },
      "source": [
        "# Document Similarity in Natural Language Processing\n",
        "\n",
        "## Overview\n",
        "Document similarity is a fundamental task in NLP, allowing us to quantify how similar two pieces of text are. It has applications in search engines, document clustering, plagiarism detection, and recommendation systems. This notebook covers essential techniques for measuring document similarity, including:\n",
        "\n",
        " * Text Preprocessing\n",
        " * Cosine Similarity\n",
        " * Jaccard Similarity\n",
        " * Word Embeddings and Semantic Similarity\n",
        "\n",
        "Let's dive in!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpT_Y4tCghui"
      },
      "source": [
        "## Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkk19LzigFRm",
        "outputId": "0aec8a29-3994-43fb-f383-26d0a21eed48"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/oysterable/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
        "from sklearn.metrics import jaccard_score\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFVuGmXgg48-"
      },
      "source": [
        "## Text Preprocessing\n",
        "\n",
        "### Why Preprocess Text?\n",
        "\n",
        "Text preprocessing is a critical step in NLP. Raw text data contains various elements that can introduce noise and reduce the effectiveness of similarity calculations. By preprocessing, we standardize and clean the text, ensuring that similarity measures capture meaningful information rather than irrelevant details.\n",
        "\n",
        "Here are the key reasons why preprocessing is essential:\n",
        "1. **Standardization**: Documents may contain the same information presented differently (e.g., \"Machine Learning\" vs. \"machine learning\"). Lowercasing ensures consistency.\n",
        "2. **Noise Reduction**: Text can include punctuation, special characters, and numbers, which often don’t contribute meaningfully to understanding the text.\n",
        "3. **Improved Tokenization**: Removing stopwords (e.g., \"and\", \"is\", \"the\") and stemming or lemmatizing words (reducing words to their root forms) makes it easier to match similar words.\n",
        "4. **Reduced Vocabulary Size**: By removing irrelevant words and standardizing text, we reduce the vocabulary size, which improves memory efficiency and speeds up computations in NLP models.\n",
        "\n",
        "Let’s walk through a simple preprocessing pipeline to clean our text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sf0pNoRXguhs",
        "outputId": "2f3050e8-5b6a-499e-c069-32c787923b60"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['raccoons generally nocturnal animals',\n",
              " 'love machine learning',\n",
              " 'raccoons struggle understand machine learning principles',\n",
              " 'artificial intelligence machine learning fastgrowing fields']"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Our sample documents\n",
        "documents = [\n",
        "    \"Raccoons are generally nocturnal animals.\",\n",
        "    \"I love machine learning.\",\n",
        "    \"Raccoons struggle to understand machine learning principles.\",\n",
        "    \"Artificial intelligence & machine learning are fast-growing fields!\"\n",
        "]\n",
        "\n",
        "import re\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess(text):\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove punctuation and special characters\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "    # Remove numbers\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "\n",
        "    # Tokenize and remove stopwords\n",
        "    words = text.split()\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Apply our preprocessing function to each document in the corpus\n",
        "documents_clean = [preprocess(doc) for doc in documents]\n",
        "documents_clean\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsK1KbBBjZgV"
      },
      "source": [
        "# Cosine Similarity\n",
        "\n",
        "Cosine similarity is one of the most commonly used similarity metrics in text analysis and NLP. It measures the similarity between two vectors by calculating the cosine of the angle between them. This metric is particularly useful when dealing with high-dimensional data, such as text, where each document can be represented as a vector of word counts or TF-IDF scores.\n",
        "\n",
        "## Why Cosine Similarity?\n",
        "\n",
        "1. **Orientation Over Magnitude**: Cosine similarity focuses on the **angle** between two vectors, not their length. This makes it ideal for text data because document length can vary significantly (e.g., short vs. long articles). Cosine similarity allows us to compare documents based on their content and structure rather than just word counts.\n",
        "   \n",
        "2. **Normalized Similarity Score**: The cosine similarity score ranges from -1 to 1, where:\n",
        "   - **1** indicates that the documents are identical in terms of content (same direction in vector space).\n",
        "   - **0** indicates no similarity (orthogonal vectors).\n",
        "   - **-1** (rare in NLP) would indicate completely opposite content (opposite directions).\n",
        "   \n",
        "   This normalized range makes cosine similarity easy to interpret, providing a consistent way to gauge similarity between documents.\n",
        "\n",
        "3. **Efficient for Sparse Data**: Text data is often sparse, meaning each document contains only a small subset of possible words. Cosine similarity is efficient for high-dimensional, sparse vectors, as it only considers words present in the documents, which reduces computation time and memory usage.\n",
        "\n",
        "4. **Suitability for Bag-of-Words Representations**: Cosine similarity works well with bag-of-words (BOW) or TF-IDF vector representations, which transform text into numerical vectors. In these vectorized forms, documents are represented by their word counts or weighted term frequencies, and cosine similarity effectively captures the similarity in terms of word usage and relevance.\n",
        "\n",
        "## Formula\n",
        "\n",
        "The cosine similarity between two vectors $A$ and $B$ is calculated as:\n",
        "\n",
        "$\n",
        "\\text{cosine similarity} = \\frac{A \\cdot B}{||A|| \\times ||B||}\n",
        "$\n",
        "\n",
        "where:\n",
        "- $A \\cdot B$ is the dot product of vectors $A$ and $B$.\n",
        "- $||A||$ and $||B||$ are the magnitudes (or Euclidean norms) of vectors $A$ and $B$.\n",
        "\n",
        "The dot product essentially measures the overlap in terms of word occurrences or term frequencies between the two documents, while the magnitudes normalize this overlap, allowing us to focus on the \"direction\" (content) rather than the \"magnitude\" (length) of each document.\n",
        "\n",
        "### Practical Example\n",
        "\n",
        "For example, consider two documents:\n",
        "- **Document 1**: \"Data science and machine learning are amazing.\"\n",
        "- **Document 2**: \"Machine learning and data science are exciting.\"\n",
        "\n",
        "Both documents contain similar content, despite minor differences in word order and vocabulary. Cosine similarity will recognize this similarity by focusing on the common terms (\"data science\", \"machine learning\") and downplaying differences due to the exact wording or order, giving a high similarity score.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2l3XlxzlkKZ"
      },
      "source": [
        "Now, let's compute the cosine similarity of our preprocessed documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOceEloMGsHL",
        "outputId": "3e8a0b72-6f0d-4cb6-dd01-07ea994ea690"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1.        , 0.        , 0.20412415, 0.        ],\n",
              "       [0.        , 1.        , 0.47140452, 0.47140452],\n",
              "       [0.20412415, 0.47140452, 1.        , 0.33333333],\n",
              "       [0.        , 0.47140452, 0.33333333, 1.        ]])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Vectorize the documents\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(documents_clean)\n",
        "\n",
        "# Compute Cosine Similarity\n",
        "cosine_sim_matrix = cosine_similarity(X)\n",
        "cosine_sim_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYL_jEP9ioof"
      },
      "source": [
        "We can see that there is a positive similarity between documents 1 and 3, documents 2 and 3, and documents 3 and 4. Let's now try Jaccard similarity and compare results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WE1PklazTqZD"
      },
      "source": [
        "# Jaccard Similarity\n",
        "\n",
        "Jaccard similarity is a metric used to measure the similarity between two sets. In NLP, it can be used to assess the similarity between two documents by treating each document as a set of unique words (or tokens). The Jaccard similarity score is defined as the ratio of the size of the intersection to the size of the union of the two sets. The score ranges from 0 to 1, where:\n",
        "\n",
        "- **1** indicates that the documents have identical content (complete overlap in terms).\n",
        "- **0** indicates no common terms between the documents.\n",
        "\n",
        "## Why Use Jaccard Similarity?\n",
        "\n",
        "Jaccard similarity is particularly useful for text analysis when we’re interested in understanding the overlap between unique terms in two documents. It’s a straightforward and interpretable metric that provides a sense of commonality, making it suitable for applications where exact word matches are important, such as:\n",
        "\n",
        "1. **Plagiarism Detection**: Jaccard similarity can highlight shared terms between two documents, which can be an indicator of copied content.\n",
        "2. **Duplicate Detection**: When identifying near-duplicate content, Jaccard similarity effectively captures the overlap of terms.\n",
        "3. **Search and Information Retrieval**: By treating documents as sets of terms, Jaccard similarity can be used to find documents that share many of the same keywords as a given query.\n",
        "\n",
        "## Jaccard Similarity Formula\n",
        "\n",
        "The Jaccard similarity between two sets $A$ and $B$ is calculated as:\n",
        "\n",
        "$$\n",
        "\\text{Jaccard Similarity} = \\frac{|A \\cap B|} {|A \\cup B|}\n",
        "$$\n",
        "\n",
        "where:\n",
        "- $|A \\cap B|$ is the number of unique terms common to both documents (the intersection).\n",
        "- $|A \\cup B|$ is the total number of unique terms present in both documents combined (the union).\n",
        "\n",
        "### Example Calculation\n",
        "\n",
        "Consider two documents:\n",
        "- **Document 1**: \"machine learning is fascinating\"\n",
        "- **Document 2**: \"machine learning is amazing\"\n",
        "\n",
        "If we treat each document as a set of unique words, we get:\n",
        "- Document 1 set: {machine, learning, is, fascinating}\n",
        "- Document 2 set: {machine, learning, is, amazing}\n",
        "\n",
        "The intersection (common terms) is {machine, learning, is} and the union is {machine, learning, is, fascinating, amazing}. Therefore, the Jaccard similarity score is:\n",
        "\n",
        "$$\n",
        "\\text{Jaccard Similarity} = \\frac{3}{5} = 0.6\n",
        "$$\n",
        "\n",
        "This indicates moderate similarity based on shared terms.\n",
        "\n",
        "## How Jaccard Similarity Compares to Cosine Similarity\n",
        "\n",
        "While both Jaccard and cosine similarity are used to measure similarity between documents, they differ thusly:\n",
        "\n",
        "1. **Focus on Unique Terms**: Jaccard similarity only considers the presence or absence of unique terms in each document, ignoring term frequency. This makes it sensitive to exact matches but less effective for capturing semantic similarity when terms overlap partially.\n",
        "\n",
        "2. **Sensitivity to Document Length**: Jaccard similarity does not account for the frequency or importance of terms within a document. In contrast, cosine similarity can be used with term frequency or TF-IDF vectors, which account for both the importance and the frequency of terms, providing a more nuanced similarity score.\n",
        "\n",
        "3. **Sparse vs. Dense Overlap**: Jaccard similarity is more suitable for binary, set-based comparisons and is often used in tasks where only exact term overlap matters. Cosine similarity, however, is generally preferred when documents contain a variety of words with some terms repeated. Cosine similarity captures the orientation of the entire vectorized representation of the document, making it more effective for capturing partial matches and overall content similarity.\n",
        "\n",
        "### When to Use Each Metric\n",
        "\n",
        "- **Use Jaccard Similarity** when looking for exact term matches or duplicate detection, where the goal is to measure pure overlap in vocabulary.\n",
        "- **Use Cosine Similarity** when you want to capture broader semantic relationships and partial matches in term usage, such as in information retrieval, recommendation systems, and general document comparison.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrfggKa_Udo0",
        "outputId": "39f70f82-48f5-45c2-8f8e-5119febed7ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1.        , 0.        , 0.11111111, 0.        ],\n",
              "       [0.        , 1.        , 0.28571429, 0.28571429],\n",
              "       [0.11111111, 0.28571429, 1.        , 0.2       ],\n",
              "       [0.        , 0.28571429, 0.2       , 1.        ]])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Compute the Jaccard Similarity between our cleaned documents\n",
        "def jaccard_similarity(doc1, doc2):\n",
        "    words_doc1 = set(doc1.split())\n",
        "    words_doc2 = set(doc2.split())\n",
        "    intersection = words_doc1.intersection(words_doc2)\n",
        "    union = words_doc1.union(words_doc2)\n",
        "    return len(intersection) / len(union)\n",
        "\n",
        "# Output a similarity matrix\n",
        "jaccard_sim_matrix = np.zeros((len(documents_clean), len(documents_clean)))\n",
        "for i in range(len(documents_clean)):\n",
        "    for j in range(len(documents_clean)):\n",
        "        jaccard_sim_matrix[i, j] = jaccard_similarity(documents_clean[i], documents_clean[j])\n",
        "\n",
        "jaccard_sim_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdMrcQ9Bw1dG"
      },
      "source": [
        "Lastly, let's talk about capturing the semantic meanings of words through word embeddings, the state of the art when it comes to document similarity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YP4eBq7_xDqt"
      },
      "source": [
        "# Word Embeddings and Semantic Similarity\n",
        "\n",
        "Traditional similarity metrics like cosine similarity and Jaccard similarity rely on counting word overlap or using vectorized representations of words based on frequency (like TF-IDF). However, these methods lack the ability to capture the **semantic meaning** of words and phrases. **Word embeddings** are a powerful alternative that represent words in continuous vector spaces, capturing semantic relationships between words based on their usage across a large corpus.\n",
        "\n",
        "## What Are Word Embeddings?\n",
        "\n",
        "Word embeddings, such as **Word2Vec** and **GloVe**, are dense, low-dimensional vector representations of words that capture semantic meaning. Each word is mapped to a unique vector where semantically similar words are located close together in the vector space. For example, in a high-quality word embedding, words like \"king\" and \"queen\" or \"doctor\" and \"nurse\" would have vectors that are close to each other, even though they may not co-occur frequently.\n",
        "\n",
        "With embeddings, we can represent an entire document as a single vector by taking the average (or another aggregation) of all word vectors in the document. This results in a **document embedding**, which we can then use to calculate similarity scores between documents in a way that captures both **syntactic** and **semantic** similarities.\n",
        "\n",
        "## Calculating Semantic Similarity with Word Embeddings\n",
        "\n",
        "1. **Convert each word to its embedding** using a pre-trained embedding model (e.g., GloVe or Word2Vec).\n",
        "2. **Aggregate word embeddings** for each document by averaging the word vectors.\n",
        "3. **Calculate similarity** between document embeddings using cosine similarity, which is effective for continuous, dense embeddings.\n",
        "\n",
        "### Where do Word Embeddings Shine?\n",
        "\n",
        "- **Captures Semantic Relationships**: Embeddings understand word meaning and context, enabling the model to recognize synonyms or related words even if they do not overlap directly in text.\n",
        "- **Contextual Understanding**: Embeddings trained on large corpora learn context from neighboring words, making them effective for capturing language nuances and domain-specific terminology.\n",
        "- **Improved Accuracy for Similar Documents**: Word embeddings generally outperform traditional similarity measures (cosine, Jaccard) in identifying conceptually similar documents, as they capture latent semantic relationships.\n",
        "\n",
        "### Comparing Word Embeddings to Other Similarity Methods\n",
        "\n",
        "| Similarity Measure       | Basis of Similarity         | Captures Semantic Meaning? | Sensitive to Term Frequency? | Typical Use Cases                                                                 |\n",
        "|--------------------------|-----------------------------|----------------------------|------------------------------|----------------------------------------------------------------------------------|\n",
        "| **Cosine Similarity**    | Angle between term vectors  | No                         | Yes                          | Document similarity with TF-IDF or bag-of-words, information retrieval           |\n",
        "| **Jaccard Similarity**   | Overlap of unique terms     | No                         | No                           | Duplicate detection, exact matches, set-based similarity                         |\n",
        "| **Euclidean Distance**   | Distance between term vectors | No                         | Yes                          | Similarity for numerical, dense vectors, sometimes used in clustering            |\n",
        "| **Word Embeddings**      | Dense vector representation of words | Yes                        | No                           | Semantic similarity, recommendation systems, contextual document similarity      |\n",
        "\n",
        "### Key Differences Between Word Embeddings and Traditional Similarity Metrics\n",
        "\n",
        "1. **Semantic Awareness**:\n",
        "   - **Traditional Metrics**: Cosine and Jaccard similarity focus on **exact term overlap** or **relative frequency** but lack semantic understanding. For instance, \"doctor\" and \"physician\" may be considered dissimilar due to lack of term overlap.\n",
        "   - **Word Embeddings**: Word embeddings capture **semantic relationships** between words. With embeddings, \"doctor\" and \"physician\" would have similar vectors, leading to higher similarity scores even if these words do not overlap directly.\n",
        "\n",
        "2. **Sensitivity to Document Size**:\n",
        "   - **Traditional Metrics**: Jaccard similarity measures pure overlap without considering document length, while cosine similarity considers relative term frequency but does not normalize for semantics.\n",
        "   - **Word Embeddings**: By averaging word vectors, embeddings offer a **document-size invariant representation** that remains consistent regardless of document length.\n",
        "\n",
        "3. **Handling Synonyms and Context**:\n",
        "   - **Traditional Metrics**: They do not handle synonyms or related terms well since these metrics depend solely on word overlap and frequency.\n",
        "   - **Word Embeddings**: Embeddings trained on large corpora capture context, making them robust to synonymy and semantic nuances.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-QbnkmxUqiE",
        "outputId": "f81f33d9-86d8-4b72-bae8-b8cdeb3ab9d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 66.0/66.0MB downloaded\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[1.0000001 , 0.35509798, 0.49974078, 0.41246545],\n",
              "       [0.35509798, 1.0000001 , 0.8658411 , 0.8233106 ],\n",
              "       [0.49974078, 0.8658411 , 1.        , 0.8203855 ],\n",
              "       [0.41246545, 0.8233106 , 0.8203855 , 1.        ]], dtype=float32)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "# Load pre-trained word vectors (e.g., GloVe)\n",
        "word_vectors = api.load(\"glove-wiki-gigaword-50\")\n",
        "\n",
        "def document_vector(doc):\n",
        "    \"\"\"Create document vectors by averaging word vectors. Ignore words not in vocabulary.\"\"\"\n",
        "    words = doc.split()\n",
        "    word_vecs = [word_vectors[word] for word in words if word in word_vectors]\n",
        "    return np.mean(word_vecs, axis=0) if word_vecs else np.zeros(50)\n",
        "\n",
        "# Generate document embeddings\n",
        "doc_vectors = np.array([document_vector(doc) for doc in documents_clean])\n",
        "\n",
        "# Compute cosine similarity on document embeddings\n",
        "embedding_cosine_sim_matrix = cosine_similarity(doc_vectors)\n",
        "embedding_cosine_sim_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybnJNFd39UR_"
      },
      "source": [
        "We can see that using word embeddings provides a much less sparse similarity matrix, compared to using similarity metrics on non-vectorized documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 11)\t1\n",
            "  (0, 4)\t1\n",
            "  (0, 9)\t1\n",
            "  (0, 0)\t1\n"
          ]
        }
      ],
      "source": [
        "print(X[0]) #precense or absence of a word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.7660975 , -0.44717848, -0.6827333 , -0.797     ,  0.38407725,\n",
              "         0.5674025 , -0.4964825 , -1.0409074 ,  0.4642875 ,  0.04673575,\n",
              "         0.29193574,  0.24002124,  1.2548425 ,  0.2546455 ,  0.26352   ,\n",
              "         0.334715  ,  0.515765  , -0.01965251, -0.9713912 , -0.33076373,\n",
              "        -0.6501725 , -0.25954026,  0.678575  ,  0.34542498,  0.27669   ,\n",
              "        -0.00653751, -0.0926375 ,  0.2078175 ,  0.59477496, -0.31192   ,\n",
              "         1.4462376 ,  0.48617497,  0.461235  , -0.7615825 , -0.0473525 ,\n",
              "         0.336995  ,  0.00744382, -0.353587  , -0.68226504,  0.2047475 ,\n",
              "        -0.80321   , -0.118825  ,  0.3130725 ,  1.1131275 ,  0.7319038 ,\n",
              "        -0.12825425,  0.02745751, -0.45865   ,  0.09084225,  0.07816499],\n",
              "       [-0.09196667,  0.27134   ,  0.01536667, -0.16772334,  0.312633  ,\n",
              "         0.46026668, -0.16913335, -0.35260653, -0.16155367,  0.51632994,\n",
              "         0.02772134,  0.18204999, -0.31387898, -0.15556599, -0.03769   ,\n",
              "        -0.174287  , -0.21033466,  0.7958934 , -0.09295699, -0.32230768,\n",
              "         0.28458   ,  0.7987333 ,  0.04109892,  0.30151334,  0.96405   ,\n",
              "        -1.0944899 , -0.84707   , -0.49298   ,  0.78761977, -0.5679566 ,\n",
              "         2.8686666 ,  0.10355001, -0.4835767 , -0.27014333, -0.01767134,\n",
              "         0.34776333,  0.04488   ,  0.16516332,  0.11263666, -0.06443667,\n",
              "         0.39272097, -0.36505935, -0.43515334,  0.4738567 ,  0.30526   ,\n",
              "        -0.10164667,  0.551768  , -0.51096   , -0.10238   ,  0.37952998],\n",
              "       [ 0.01460333, -0.20843367, -0.02483744, -0.34463167,  0.31930467,\n",
              "         0.3448485 , -0.01444667, -0.56776667, -0.28742182,  0.080241  ,\n",
              "         0.07899667,  0.15704499, -0.23420282, -0.05753233, -0.2252285 ,\n",
              "         0.15804933,  0.177381  ,  0.25971502,  0.14343   , -0.202919  ,\n",
              "        -0.1844514 ,  0.40330335, -0.02316388,  0.12063333,  0.701005  ,\n",
              "        -0.89416504, -0.5948567 , -0.53237504,  0.60353154, -0.32897016,\n",
              "         2.1641166 ,  0.35301837, -0.610775  , -0.6829683 , -0.147054  ,\n",
              "         0.11726334, -0.23785867, -0.05808001, -0.10559001,  0.2555    ,\n",
              "        -0.20405298, -0.46085632,  0.01058667,  0.70748   ,  0.21035333,\n",
              "         0.16329001,  0.35204402,  0.19315   , -0.03783016,  0.083375  ],\n",
              "       [ 0.28150442,  0.15020001,  0.20298597,  0.22941141,  0.01855845,\n",
              "         0.17644802, -0.17394   , -0.578174  ,  0.3264678 , -0.02165999,\n",
              "         0.2507946 ,  0.06688559, -0.0283054 , -0.053092  , -0.43920198,\n",
              "         0.2430038 ,  0.0927572 ,  0.63152623, -0.08094241, -0.2298048 ,\n",
              "         0.262716  ,  0.36865   ,  0.27078846, -0.321062  ,  0.33684438,\n",
              "        -0.946056  , -0.3762014 , -0.2291548 ,  0.47352782, -0.10147159,\n",
              "         2.70074   , -0.33067998, -0.423072  , -0.884634  ,  0.0770338 ,\n",
              "         0.698552  , -0.269936  ,  0.60719407,  0.12104001,  0.30151922,\n",
              "         0.242968  , -0.1942436 , -0.1157694 ,  0.60272324,  0.353338  ,\n",
              "        -0.2171228 ,  0.41579318,  0.28213   , -0.23265   , -0.045262  ]],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "doc_vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the two vectors\n",
        "print(embedding_cosine_sim_matrix[0])\n",
        "\n",
        "v1=np.array(embedding_cosine_sim_matrix[1])\n",
        "v2=np.array(embedding_cosine_sim_matrix[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzDMUqremmbn"
      },
      "source": [
        "# References\n",
        "\n",
        "1. https://courses.cs.washington.edu/courses/cse573/12sp/lectures/17-ir.pdf\n",
        "2. https://www.newscatcherapi.com/blog/ultimate-guide-to-text-similarity-with-python\n",
        "3. https://www.polarsparc.com/xhtml/Document-Similarity-NLP.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VaLzKnHcm8KF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text: 'The service was not bad, but the food was excellent.'\n",
            "Sentiment: Positive (Score: 4)\n"
          ]
        }
      ],
      "source": [
        "# A simple example of a lexicon (dictionary of sentiment scores)\n",
        "lexicon = {\n",
        "    \"great\": 2,\n",
        "    \"excellent\": 3,\n",
        "    \"bad\": -2,\n",
        "    \"terrible\": -3,\n",
        "    \"not\": -1  # negation handling\n",
        "}\n",
        "\n",
        "# Text preprocessing (removing punctuation, lowercasing, tokenizing)\n",
        "def preprocess(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    return text.split()\n",
        "\n",
        "# Calculating sentiment score\n",
        "def calculate_sentiment(text, lexicon):\n",
        "    tokens = preprocess(text)\n",
        "    sentiment_score = 0\n",
        "    negation_flag = False\n",
        "\n",
        "    for token in tokens:\n",
        "        if token in lexicon:\n",
        "            score = lexicon[token]\n",
        "            # Handle negation\n",
        "            if negation_flag:\n",
        "                score = -score\n",
        "                negation_flag = False  # Reset after applying negation\n",
        "            sentiment_score += score\n",
        "        if token == \"not\":  # Set flag for negation\n",
        "            negation_flag = True\n",
        "\n",
        "    # Determine sentiment category\n",
        "    if sentiment_score > 0:\n",
        "        sentiment = \"Positive\"\n",
        "    elif sentiment_score < 0:\n",
        "        sentiment = \"Negative\"\n",
        "    else:\n",
        "        sentiment = \"Neutral\"\n",
        "\n",
        "    return sentiment, sentiment_score\n",
        "\n",
        "# Example usage\n",
        "text = \"The service was not bad, but the food was excellent.\"\n",
        "sentiment, score = calculate_sentiment(text, lexicon)\n",
        "print(f\"Text: '{text}'\")\n",
        "print(f\"Sentiment: {sentiment} (Score: {score})\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
